{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a517e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import datafree\n",
    "%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a8453e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 07:05:48 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 69%   64C    P2   321W / 350W |  21749MiB / 24576MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 72%   65C    P2   329W / 350W |  16787MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 97%   70C    P2   333W / 350W |  16787MiB / 24576MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 73%   69C    P2   338W / 350W |  21749MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 70%   64C    P2   333W / 350W |  15901MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 52%   58C    P2   199W / 350W |  12003MiB / 24576MiB |     94%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     33881      C   python                          21747MiB |\n",
      "|    1   N/A  N/A     28761      C   python                          16785MiB |\n",
      "|    2   N/A  N/A     29126      C   python                          16785MiB |\n",
      "|    3   N/A  N/A     37043      C   python                          21747MiB |\n",
      "|    4   N/A  N/A     34689      C   python                          15899MiB |\n",
      "|    5   N/A  N/A     22603      C   python                          12001MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "821287c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time(h)  Acc@1      method  size\n",
      "0  11.900000  81.10        DAFL   300\n",
      "1  23.458333  89.46         ADI   300\n",
      "2  12.972222  90.84         DFQ   300\n",
      "3  69.583333  91.13         CMI   300\n",
      "4  13.050000  91.61      CuDFKD   300\n",
      "5  14.466667  92.04  AdaDFKD(S)  5000\n",
      "6  15.566667  92.19  AdaDFKD(G)  5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "accs = {\n",
    "    'DAFL': [11.9, 81.10],\n",
    "    'ADI': [(28 / 60 + 9 / 3600)*50, 89.46],\n",
    "    'DFQ': [(0.25 + 34/3600)*50, 90.84],\n",
    "    'CMI': [(1 + 23.5/60)*50, 91.13],\n",
    "    'CuDFKD': [13 + 3/60, 91.61],\n",
    "    'AdaDFKD(S)': [14 + 28/60, 92.04],\n",
    "    'AdaDFKD(G)': [15 + 34/60, 92.19]\n",
    "}\n",
    "\n",
    "acc = {\n",
    "    'Time(h)': [11.9, (28 / 60 + 9 / 3600)*50,(0.25 + 34/3600)*50, (1 + 23.5/60)*50, 13 + 3/60,14 + 28/60, 15 + 34/60 ],\n",
    "    'Acc@1':[81.10,  89.46, 90.84, 91.13, 91.61, 92.04, 92.19],\n",
    "    'method': accs.keys(),\n",
    "    'size': [300, 300, 300, 300, 300, 5000, 5000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(acc)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6d28ded",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-f2d0959c242d>:5: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([ 0, 8, 16, 32, 64])\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {\"AdaDFKD(S)\": \"*\", \"AdaDFKD(G)\": \"*\", \"CuDFKD\": \"o\", \"CMI\":\"o\", \"DFQ\":\"o\", \"ADI\":\"o\", \"DAFL\":\"o\"}\n",
    "ax = sns.scatterplot(data=df, x='Time(h)', y='Acc@1', style='method', hue='method', markers=markers, s=[50, 50, 50, 50, 50, 300, 300])\n",
    "ax.set_xscale('log', base=2, subs=[1.25, 1.5])\n",
    "# ax.set_xlim(7, 64)\n",
    "ax.set_xticklabels([ 0, 8, 16, 32, 64])\n",
    "ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f81d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False\n",
    "gpu = 5\n",
    "# gpu ='0,1'\n",
    "batch_size = 128\n",
    "workers = 8\n",
    "num_classes = 10\n",
    "# num_classes = 100\n",
    "# num_classes = 200\n",
    "def prepare_model(model):\n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "        return model\n",
    "    elif distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if gpu is not None:\n",
    "#             torch.cuda.set_device(gpu)\n",
    "            model.cuda()\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            batch_size = int(batch_size / 1)\n",
    "            workers = int((workers + 1 - 1) / 1)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[int(x) for x in gpu.split(',')])\n",
    "            return model\n",
    "        else:\n",
    "            model.cuda()\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "            return model\n",
    "    elif gpu is not None:\n",
    "        torch.cuda.set_device(gpu)\n",
    "        model = model.cuda(gpu)\n",
    "        return model\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddea5407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10,CIFAR100\n",
    "import datafree\n",
    "import registry\n",
    "from torch import nn\n",
    "student = registry.get_model('resnet18', num_classes=num_classes)\n",
    "teacher = registry.get_model('resnet34', num_classes=num_classes, pretrained=True).eval()\n",
    "# student = registry.get_model('wrn40_1', num_classes=num_classes)\n",
    "# student= registry.get_model('wrn16_2', num_classes=num_classes)\n",
    "# teacher = registry.get_model('wrn40_2', num_classes=num_classes)\n",
    "# normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['tiny_imagenet'])\n",
    "# normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['cifar10'])\n",
    "normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['cifar100'])\n",
    "student = prepare_model(student)\n",
    "\n",
    "# teacher = teacher.to(gpu)\n",
    "# teacher.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "# num_ftrs = teacher.fc.in_features\n",
    "# teacher.fc = nn.Linear(num_ftrs, 200)\n",
    "# teacher.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "# teacher.maxpool = nn.Sequential()\n",
    "teacher = prepare_model(teacher)\n",
    "# ckpt = torch.load('../checkpoints/scratch/tiny_imagenet_resnet34_imagenet.pth', map_location='cpu')\n",
    "# dict_ckpt = dict()\n",
    "# for k, v in ckpt['state_dict'].items():\n",
    "#     dict_ckpt['.'.join(k.split('.')[1:])] = v\n",
    "# teacher.load_state_dict(dict_ckpt)\n",
    "\n",
    "teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar10_resnet34.pth', map_location='cpu')['state_dict'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar10_wrn40_2.pth', map_location='cpu')['state_dict'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar100_wrn40_2.pth', map_location='cpu')['state_dict'])\n",
    "# print(ckpt['best_acc1'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar100_resnet34.pth', map_location='cpu')['state_dict'])\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41af454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/data/lijingru/DFKD/run/cr4_sim_normalize_pos_c': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/lijingru/DFKD/run/cr4_sim_normalize_pos_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353c21e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-53fb9dbb976e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manchor_bank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# all_anchor = anchor_bank.reshape(-1, 512)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_bank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt'"
     ]
    }
   ],
   "source": [
    "anchor_bank = torch.load('/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt', map_location='cpu')\n",
    "# all_anchor = anchor_bank.reshape(-1, 512)\n",
    "print(anchor_bank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b27168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def difficulty_loss(anchor, teacher, t_out, logit_t, ds='cifar10', hard_factor=0., tau=10, device='cpu', d_neg_fea=None):\n",
    "    batch_size = anchor.size(0)\n",
    "    with torch.no_grad():\n",
    "        # t_logit, anchor_t_out = teacher(anchor.to(device).detach(), return_features=True)\n",
    "        t_logit = teacher(anchor.to(device).detach())\n",
    "        anchor_t_out = anchor.to(device)\n",
    "        # pseudo_label = pseudo_label.argmax(1)\n",
    "    # loss = 0.\n",
    "    pos_loss = 0.\n",
    "    neg_loss = 0.\n",
    "    if ds == 'cifar10':\n",
    "        normalized_anchor_t_out, normalized_t_out = F.normalize(anchor_t_out, dim=1), F.normalize(t_out, dim=1)\n",
    "        d = torch.mm(normalized_anchor_t_out, normalized_t_out.T)\n",
    "        N_an, N_batch = d.size()\n",
    "        \n",
    "        sorted_d, indice_d = torch.sort(d, dim=1)\n",
    "        d_pos = sorted_d[:, -int(0.05 * N_batch):]\n",
    "        d_neg = sorted_d[:, :-int(0.05 * N_batch)]\n",
    "        # n_neg = d_neg.size(1)\n",
    "        d_mask = torch.zeros_like(indice_d)\n",
    "        d_mask = d_mask.scatter(1, indice_d[:, -int(0.1*N_batch):], 1)\n",
    "        p_t_anchor = torch.softmax(t_logit, 1)\n",
    "        p_t_batch = torch.softmax(logit_t, 1)\n",
    "        kld_matrix = -torch.mm(p_t_anchor, p_t_batch.T.log()) + torch.diag(torch.mm(p_t_anchor, p_t_anchor.T.log())).unsqueeze(1)\n",
    "        l_kld = ((kld_matrix * d_mask).sum(1) / d_mask.sum(1)).mean()\n",
    "        # Get positive DA index\n",
    "        p_pos = torch.softmax(d_pos / tau, dim=1)\n",
    "        p_da_pos = torch.quantile(p_pos, q=1-hard_factor, dim=1).unsqueeze(1)\n",
    "        pos_loss = torch.sum(p_pos * torch.log(p_pos / p_da_pos).abs(), dim=1).mean()\n",
    "        # Get Negative DA index\n",
    "        \n",
    "        if d_neg_fea is not None:\n",
    "            d = torch.cat([d_neg, d_pos], 1)\n",
    "            d_mask = torch.zeros_like(d)\n",
    "#             d_mask[:, ]\n",
    "        p_total = torch.softmax(d / tau, dim=1)\n",
    "        # Out supervised loss.\n",
    "        print(d_mask, d_mask.shape)\n",
    "        neg_loss = -((d_mask * p_total.log()).sum(1) / (d_mask.sum(1))).mean()\n",
    "#         print(pos_loss, neg_loss, l_kld)\n",
    "        \n",
    "        return pos_loss, indice_d, neg_loss, l_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3874fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGAN_Generator_CIFAR10(\n",
       "  (project): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Linear(in_features=512, out_features=16384, bias=True)\n",
       "  )\n",
       "  (main): Sequential(\n",
       "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg = datafree.models.generator.DCGAN_Generator_CIFAR10(nz=512, ngf=64, nc=3, img_size=32, d=2, cond=False, type='normal', widen_factor=1)\n",
    "tg.load_state_dict(torch.load('/data1/lijingru/DFKD/checkpoints/datafree-improved_cudfkd/cifar10-resnet34-resnet18--infonce_s_exp6.pth', map_location='cpu')['G'])\n",
    "prepare_model(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dec2cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 2, 8, 2, 6, 0, 6, 0, 2, 8], device='cuda:5')\n"
     ]
    }
   ],
   "source": [
    "student.load_state_dict(torch.load('/data1/lijingru/DFKD/checkpoints/datafree-improved_cudfkd/cifar10-resnet34-resnet18--infonce_s_exp6.pth', map_location='cpu')['state_dict'])\n",
    "z = torch.randn(512, 512).to(gpu)\n",
    "x = normalizer(tg(z))\n",
    "t_out, t_feat = teacher(x, return_features=True)\n",
    "\n",
    "s_out, s_feat= student(x, return_features=True)\n",
    "tau = 0.07\n",
    "t_feat = torch.nn.functional.normalize(t_feat, dim=-1)\n",
    "s_feat = torch.nn.functional.normalize(s_feat, dim=-1)\n",
    "\n",
    "l_neg = t_feat @ s_feat.T\n",
    "_, indice_neg = torch.sort(l_neg, dim=1)\n",
    "\n",
    "balance = torch.nn.functional.cross_entropy(t_out, t_out.argmax(1), reduction='none')\n",
    "_ , index = torch.sort(balance)\n",
    "img_anchor = x[index[:10]].cpu()\n",
    "label = t_out[index[:10]].argmax(1)\n",
    "print(label)\n",
    "new_img = x.cpu()[indice_neg[index[:10]]]\n",
    "imgs = new_img.reshape(5120, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc50f321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5971e-02, 4.9913e-03, 4.8435e-04, 1.1491e-04, 6.2307e-02, 5.7498e-03,\n",
      "        1.7951e-04, 6.6437e-04, 4.7887e-04, 6.1286e-01, 1.2127e-02, 3.6090e-04,\n",
      "        1.7019e-03, 1.2994e-05, 2.5305e-02, 1.5854e-04, 4.3419e-04, 1.8120e-05,\n",
      "        1.4477e-01, 3.5065e-04, 1.4989e-03, 1.1420e-04, 2.0437e-01, 2.1738e-02,\n",
      "        3.8385e-05, 7.2150e-01, 8.9808e-04, 1.7343e-04, 3.8223e-04, 1.4066e-04,\n",
      "        3.9219e-05, 8.0208e-04, 5.1520e-01, 1.2898e-04, 1.2065e-01, 3.7653e-03,\n",
      "        2.8852e-03, 6.1629e-05, 4.8340e-04, 5.2118e-02, 2.6861e-02, 2.1320e-01,\n",
      "        2.8856e-04, 2.6995e-01, 4.6598e-01, 2.6723e-04, 5.1318e-04, 2.8630e-03,\n",
      "        3.2706e-04, 3.8578e-03, 2.0919e-01, 2.8749e-04, 4.1369e-04, 6.8200e-04,\n",
      "        5.4666e-03, 1.8004e-02, 6.1529e-04, 1.0475e+00, 3.0418e-04, 4.0590e-02,\n",
      "        2.5578e-02, 2.0443e-01, 8.7438e-04, 4.4751e-02, 1.0169e-02, 2.3386e-04,\n",
      "        7.3311e-05, 1.8726e-04, 1.7403e-04, 4.6731e-04, 1.4777e-03, 7.5695e-05,\n",
      "        9.5024e-04, 7.8147e-04, 3.0604e-01, 2.2397e-04, 4.5861e-04, 8.3168e-03,\n",
      "        7.1237e-03, 7.8742e-04, 9.9654e-05, 1.8704e-01, 4.0932e-02, 2.4328e-04,\n",
      "        1.7641e-03, 3.4072e-03, 3.4778e-02, 1.4709e-04, 4.3673e-02, 4.9424e-01,\n",
      "        1.7933e-01, 3.1049e-04, 6.2306e-01, 3.1669e-04, 5.9131e-01, 1.0466e-04,\n",
      "        2.5961e-01, 1.2335e-03, 5.7597e-04, 2.1134e-04, 4.2249e-03, 2.0417e-01,\n",
      "        2.8888e-02, 8.4829e-04, 5.0568e-04, 1.2931e-02, 2.0357e-01, 1.1072e+00,\n",
      "        4.4622e-04, 4.9416e-03, 9.9050e-04, 3.6802e-01, 3.4465e-01, 2.8215e-03,\n",
      "        5.7254e-01, 1.8236e-02, 4.3749e-05, 1.9860e-03, 1.5424e-04, 1.3196e-04,\n",
      "        1.4101e-04, 2.1026e-04, 6.1391e-05, 6.8365e-03, 5.6902e-02, 3.1728e-04,\n",
      "        1.0644e-02, 2.0434e-01, 6.0791e-02, 2.8940e-04, 1.4796e-03, 3.7311e-01,\n",
      "        2.7584e-02, 3.2038e-02, 1.0847e-04, 1.2504e-04, 1.1483e-02, 4.6781e-03,\n",
      "        2.6619e-01, 1.3351e-05, 1.4029e-03, 2.9173e-01, 1.3381e-01, 2.5376e-04,\n",
      "        6.3971e-04, 2.5128e-02, 1.5957e-03, 3.2309e-01, 1.6326e-02, 2.5736e-03,\n",
      "        7.0273e-04, 1.4221e-04, 1.8642e-02, 1.5079e-04, 6.9657e-01, 8.7377e-05,\n",
      "        9.0357e-05, 1.0689e-02, 8.5568e-04, 7.9415e-02, 1.9870e-04, 1.0015e-01,\n",
      "        2.4387e-04, 3.2312e-04, 1.0700e-02, 1.9970e-01, 4.4610e-04, 2.0678e-03,\n",
      "        1.9398e-01, 1.9437e-03, 2.4256e-04, 6.3459e-04, 2.2635e-04, 8.0601e-04,\n",
      "        1.0898e-03, 7.0927e-05, 2.0947e-02, 3.0899e-01, 9.7455e-02, 9.6441e-04,\n",
      "        6.0469e-04, 9.1549e-05, 6.0838e-04, 6.3775e-01, 1.0997e-01, 1.9432e-02,\n",
      "        2.8804e-02, 6.2583e-05, 6.6807e-03, 8.4059e-02, 1.0931e-04, 4.3454e-04,\n",
      "        1.8374e-03, 5.6191e-04, 1.1612e-01, 3.1319e-01, 8.5206e-01, 9.6361e-02,\n",
      "        2.9018e-01, 3.9942e-01, 5.4070e-03, 6.4734e-01, 1.4483e-04, 3.3826e-04,\n",
      "        3.4966e-01, 8.6788e-03, 9.8321e-02, 2.5960e-04, 3.0143e-04, 5.3094e-04,\n",
      "        1.6367e-02, 7.0450e-05, 3.4229e-01, 2.1315e-03, 1.3885e-02, 3.2467e-04,\n",
      "        3.2097e-02, 2.2401e-01, 9.8920e-03, 4.5418e-05, 2.9804e-03, 8.3424e-04,\n",
      "        6.2196e-04, 5.3091e-01, 5.0520e-04, 3.3506e-03, 3.9245e-03, 1.1400e-02,\n",
      "        1.6482e-02, 6.9219e-02, 2.6318e-04, 7.7397e-03, 5.0186e-05, 3.4148e-04,\n",
      "        2.2977e-01, 3.1121e-04, 1.0002e-02, 7.0450e-05, 4.5000e-02, 2.1085e-01,\n",
      "        3.8517e-01, 7.3440e-03, 2.7727e-03, 2.0442e-04, 3.2975e-03, 1.0883e-04,\n",
      "        5.1453e-01, 1.3068e-03, 5.4690e-04, 1.9148e-03, 9.9669e-04, 1.9300e-02,\n",
      "        1.0790e-03, 1.4280e-04, 6.2947e-04, 4.8947e-04, 9.9633e-04, 2.4609e-03,\n",
      "        3.7079e-04, 1.7916e-04, 3.1037e-01, 6.0676e-05, 1.2676e-03, 2.3948e-02,\n",
      "        6.2415e-02, 4.2060e-04, 4.0556e-02, 6.0683e-04, 1.4645e-02, 7.0875e-02,\n",
      "        2.3819e-03, 8.9430e-01, 3.2050e-04, 5.1222e-01, 4.0420e-01, 2.8513e-01,\n",
      "        4.0857e-04, 7.9598e-03, 4.9122e-01, 8.8449e-05, 7.3182e-02, 4.3131e-03,\n",
      "        2.1703e-02, 1.0408e-01, 2.5446e-03, 6.4376e-04, 2.6690e-01, 1.1728e-01,\n",
      "        2.4576e-02, 1.2439e-01, 1.2080e-01, 6.7259e-04, 3.0160e-01, 9.0120e-02,\n",
      "        2.0082e-03, 5.0373e-02, 2.0659e-01, 6.2303e-04, 3.7413e-04, 4.0030e-03,\n",
      "        1.4566e-04, 3.5371e-02, 1.4684e-01, 7.3669e-05, 1.5889e-02, 2.8504e-02,\n",
      "        2.8014e-05, 4.1461e-02, 1.9310e-04, 1.6447e-03, 5.8026e-04, 4.0338e-03,\n",
      "        4.6874e-04, 5.4883e-03, 2.7677e-04, 4.0247e-01, 2.2964e-02, 2.9161e-02,\n",
      "        3.4227e-01, 5.3643e-05, 7.9033e-05, 1.5069e-01, 5.6001e-04, 8.2185e-04,\n",
      "        1.8845e-04, 1.4409e-03, 5.2169e-02, 2.5519e-04, 2.5629e-03, 5.2057e-04,\n",
      "        3.6742e-02, 1.7129e-03, 7.2596e-05, 5.1688e-04, 2.3613e-04, 1.0003e-01,\n",
      "        2.6044e-04, 8.2254e-03, 1.1932e-04, 2.2372e-02, 3.9839e-02, 6.2339e-04,\n",
      "        8.6345e-03, 1.5202e-01, 1.4554e-04, 3.9772e-04, 1.5384e-03, 2.0268e-03,\n",
      "        9.3337e-05, 2.4602e-04, 2.6807e-04, 1.1421e-03, 3.4303e-04, 2.0981e-05,\n",
      "        2.6294e-03, 1.3577e-04, 3.9949e-02, 7.2119e-05, 3.9701e-04, 9.7747e-05,\n",
      "        4.8384e-01, 1.3351e-04, 2.2981e-04, 1.6736e-04, 5.3640e-02, 3.9297e-01,\n",
      "        6.2828e-03, 2.7817e-01, 1.4983e-04, 6.9151e-03, 5.3732e-03, 5.1402e-04,\n",
      "        4.0892e-04, 1.8171e-03, 1.0062e-03, 1.4654e-01, 1.0728e-04, 2.0836e-04,\n",
      "        1.2404e-01, 5.3404e-05, 2.9064e-03, 6.3298e-05, 6.9139e-05, 7.7960e-05,\n",
      "        3.0210e-03, 1.0001e-01, 1.5785e-03, 9.4171e-05, 4.5015e-04, 5.5817e-03,\n",
      "        4.5529e-02, 5.7335e-04, 4.1608e-01, 1.0037e-04, 4.7843e-01, 5.6287e-04,\n",
      "        3.6259e-01, 1.0917e-02, 6.8436e-02, 1.2681e-01, 3.3223e-03, 1.4435e-04,\n",
      "        1.1833e-03, 7.3120e-04, 2.7701e-01, 2.0037e-04, 4.8280e-04, 2.0318e-03,\n",
      "        1.0101e-01, 9.6477e-04, 1.7228e-01, 8.0225e-05, 7.5169e-04, 3.5510e-02,\n",
      "        3.8471e-02, 4.3932e-01, 2.3745e-01, 1.1719e-02, 2.9166e-04, 2.6610e-03,\n",
      "        4.6555e-03, 4.2572e-04, 4.8008e-03, 3.2150e-03, 1.2163e-02, 8.2609e-05,\n",
      "        5.9122e-04, 8.3038e-01, 3.1049e-04, 4.0282e-01, 1.8142e-04, 4.7017e-04,\n",
      "        2.2228e-02, 9.3170e-02, 9.9219e-03, 1.8905e-01, 2.3184e-04, 1.2627e-03,\n",
      "        1.7213e-03, 1.0465e-03, 2.1777e-04, 9.6446e-03, 2.6950e-04, 1.0540e-01,\n",
      "        3.4256e-01, 5.9742e-04, 6.2481e-03, 4.0234e-03, 1.8392e-04, 2.9993e-02,\n",
      "        4.7887e-04, 4.8268e-02, 1.0443e-01, 2.1126e-01, 7.9718e-02, 1.2314e-04,\n",
      "        1.1660e-02, 5.4154e-04, 5.3184e-01, 6.9177e-03, 3.7073e-05, 3.7603e-04,\n",
      "        1.4852e-03, 1.4514e-03, 4.3206e-03, 1.6462e-02, 3.7794e-04, 4.6952e-02,\n",
      "        2.0303e-03, 2.8451e-04, 8.9641e-05, 1.4604e-01, 7.7301e-02, 3.3269e-01,\n",
      "        2.3219e-04, 4.5867e-02, 9.9586e-02, 1.1522e-03, 1.8120e-05, 2.3863e-03,\n",
      "        2.4733e-04, 5.1688e-04, 6.8951e-03, 4.9722e-04, 1.1236e-01, 2.1169e-04,\n",
      "        1.5794e-04, 1.2385e-04, 3.9736e-04, 3.0632e-04, 3.2086e-04, 1.2119e-03,\n",
      "        6.9549e-01, 2.2534e-03, 1.9870e-04, 6.2732e-04, 2.1940e-03, 2.0418e-04,\n",
      "        1.4364e-04, 1.2963e-01, 5.3524e-05, 3.8235e-04, 4.5903e-01, 3.2879e-03,\n",
      "        2.3579e-02, 4.2346e-04, 7.2866e-01, 2.3936e-03, 4.1262e-04, 2.2457e-04,\n",
      "        3.6078e-04, 1.6652e-04], device='cuda:5', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb60d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100)\n",
      "tensor(0.1100)\n",
      "tensor(0.2100)\n",
      "tensor(0.3100)\n",
      "tensor(0.4100)\n",
      "tensor(0.5100)\n",
      "tensor(0.6100)\n",
      "tensor(0.7100)\n",
      "tensor(0.8100)\n",
      "tensor(0.9100)\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image,make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "img_list = []\n",
    "for i in torch.arange(0.01, 1.01, 0.1):\n",
    "    print(i)\n",
    "    img_list.append(new_img[:, -int(512 * i), :, :, :].unsqueeze(1))\n",
    "    \n",
    "img_list = torch.cat(img_list, 1)\n",
    "this_img = img_list.reshape(100, 3, 32, 32)\n",
    "img = make_grid(img_anchor, nrow=1, padding=2, normalize=True)\n",
    "neg_img = make_grid(this_img, nrow=10, padding=2, normalize=True)\n",
    "print(img.max(), img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bea2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d563ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(img, 'anchor.jpg')\n",
    "save_image(neg_img, 'neg2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04d5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
