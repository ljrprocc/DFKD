{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a517e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import datafree\n",
    "%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a8453e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  4 14:32:27 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 67%   62C    P2   320W / 350W |  21749MiB / 24576MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 71%   64C    P2   329W / 350W |  21725MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 97%   70C    P2   328W / 350W |  14683MiB / 24576MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 71%   68C    P2   330W / 350W |  14683MiB / 24576MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 68%   63C    P2   326W / 350W |  21749MiB / 24576MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 30%   19C    P8     4W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3798      C   python                          21747MiB |\n",
      "|    1   N/A  N/A      4013      C   python                          21723MiB |\n",
      "|    2   N/A  N/A     45128      C   python                          14681MiB |\n",
      "|    3   N/A  N/A     29147      C   python                          14681MiB |\n",
      "|    4   N/A  N/A     45982      C   python                          21747MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821287c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time(h)  Acc@1      method\n",
      "0  11.900000  81.10        DAFL\n",
      "1  23.458333  89.46         ADI\n",
      "2  12.972222  90.84         DFQ\n",
      "3  69.583333  91.13         CMI\n",
      "4  13.050000  91.61      CuDFKD\n",
      "5  14.466667  92.04  AdaDFKD(S)\n",
      "6  15.566667  92.19  AdaDFKD(G)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "accs = {\n",
    "    'DAFL': [11.9, 81.10],\n",
    "    'ADI': [(28 / 60 + 9 / 3600)*50, 89.46],\n",
    "    'DFQ': [(0.25 + 34/3600)*50, 90.84],\n",
    "    'CMI': [(1 + 23.5/60)*50, 91.13],\n",
    "    'CuDFKD': [13 + 3/60, 91.61],\n",
    "    'AdaDFKD(S)': [14 + 28/60, 92.04],\n",
    "    'AdaDFKD(G)': [15 + 34/60, 92.19]\n",
    "}\n",
    "\n",
    "acc = {\n",
    "    'Time(h)': [11.9, (28 / 60 + 9 / 3600)*50,(0.25 + 34/3600)*50, (1 + 23.5/60)*50, 13 + 3/60,14 + 28/60, 15 + 34/60 ],\n",
    "    'Acc@1':[81.10,  89.46, 90.84, 91.13, 91.61, 92.04, 92.19],\n",
    "    'method': accs.keys()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(acc)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d28ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1BhZ2VzIDIgMCBSIC9UeXBlIC9DYXRhbG9nID4+CmVuZG9iago4IDAgb2JqCjw8IC9FeHRHU3RhdGUgNCAwIFIgL0ZvbnQgMyAwIFIgL1BhdHRlcm4gNSAwIFIKL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0gL1NoYWRpbmcgNiAwIFIKL1hPYmplY3QgNyAwIFIgPj4KZW5kb2JqCjExIDAgb2JqCjw8IC9Bbm5vdHMgMTAgMCBSIC9Db250ZW50cyA5IDAgUgovR3JvdXAgPDwgL0NTIC9EZXZpY2VSR0IgL1MgL1RyYW5zcGFyZW5jeSAvVHlwZSAvR3JvdXAgPj4KL01lZGlhQm94IFsgMCAwIDM4Mi41OTA2MjUgMjYwLjkxMTg3NSBdIC9QYXJlbnQgMiAwIFIgL1Jlc291cmNlcyA4IDAgUgovVHlwZSAvUGFnZSA+PgplbmRvYmoKOSAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDEyIDAgUiA+PgpzdHJlYW0KeJzNWkGPHbcNvs+v0HF9iFaiJEq61c7WRt0WqJMFcqh7KNYbO8ZuAidt/VP7d/ppZp5Ezs7OvqA+2IDh9zgc8iP1iSL17M3H6fK5N+9/M858xN/PxptX5vLq9j8/3dx+9+qFufltcpDfT6GQTdUxJXy9k1+Jna3el5wgd/rrh2n6eYJ9vPMKpt9PU3Sn9wJbyrMerOdkw1Z8J8WUgs0ns8OIEsPbj9On6Y35ZPbchBBtMeSzjdH8emt+MD+by+c0R289+cSFKafJ2cjrn4wn2aVSKCSq5tf3CAJ5srGsqZIvGvnitHkRWWiJ9CYlW1wpjosvZCJbn1LyPnBgc3NvLv/mzNUvTdvGWlyoMN9QuBSr85VdWVAcPe6+vGdbs/PZp0hsfKzWeXKFasrSG6LItFqAMQQTk4P5aNQTOH5Uc9podgzfeEfWOx+hlhLyH7EymUsJIXmFoczRIJehuUHaoveZ0/xlznDECzOGRzSnjWbHQKUiXbHkyPBskvVcXa4xUFYI0ppRri2/7uSlkWD2ELNbs/CI5rTRHFmgUsCOyJ5iDMkUi1XPUAQLNIR1HXOB4RCWlBI+r0HGvOZgX3HaKA4qZJvZ11y4ZDLZMscIapRa9RqcjEaz3QazNPiQ1zXY15w2mgMAWQ4OTkH7bPAlB2afc5JEfDOdNqQ5bTXGTmvVA5LJx4TwHNKoqocUx1E9phdw/hkFoUH4ZsHANjfFtnyGyNYE59OL61bkLORzxbh+N12+hLIz1z9OF/TMXH+cig0ee4ybZdc0Lv47yz1yD4cR8fYnfn7CNjAhYPGKWx8090iRb9XJFpo/rE7z7HOx8Mdr5GNOwAR2YXt5HfYQHgddGcn27JB8kPK8qMNXETVHm7G7wRcVtxAfRk6ortQUGeX23PWOX0PkwQVL3vvq9TEpxDrydrZxCKVsXhDiw1QFnBR+VkR5qmemir+KVLG35HwomiRSfLw9UJh5bTIqFGeXc+RmhOoWmH83F9fPDFU7I7/46f727cWHt8+emX+Y69cnUGgNRIPCOPxqjjjqW5dj3Va6y1sYWQAnHBrOoZ7iDD8AVegIQs22RNReVhCG9BhCjdbh7IRi9UcQ4hEEUAsHcPJohSQGIT4G4VvOa8EZFzgdwuBDGFytB79T0DCG+AkYjH4UR3ueT/8jGOUIBjkUMJSvnBUMIT6GQQ4tdoUxVP8QDmBUdwgDH2P0mhZd+AQE7DV0EOg6sMMOIShqfpqWlrB1BC3YMK9tRrGhJ/bd82ethZl9X9zc/MFLq2ReL/NLC3AzvezPG48MENP3+5PI/aOTCN74XRON0heWDj1cPg9LT/S6zVD4+3kOdZ2oKAeL9rNpRy8LYDnZG2KMVOB6JnC9CHHITujWUDAuKGE4ad5MQuwTduVSxe+UvI2AxWHQMMKdR0VetQU2Ib2RoQj5HeSYNsuMSsgBaWh3j1I68DXbXT7CuVPiHrrwN5K0m+ebNnS+eNC1rv2qPGCdx9iSFsanNrCFY8Lf3/7rwy/v9P59ZNZ8MKSeOZV+dzC/bm2CZyX1xIZk3bx86MYKemqPsywKMRUM2Wi6/KIbiEJEV4Gj1mEwqIu0lFhDW5l2AruUMZJiDEb1ycnPut1bRteDFmQjLauzxYIQF+dLWtx1u9UmjlVjiC36jPm5WRiAIcZ46GcQIzas+Sm2kYcuvJnTg/mCmJVuRK+DUWhjFr2Nc5gANxjAy5DRFyi8tBsa7eeBdpMm7I78DgxqLQZguXAjNrHGO3xY94Nbr3webIIgXwlP1PwrUfOfv/yL3Av/x/0IWO+nw+sTRXVq0/XcwmquD7nkDqScXESqJdEI9cIHJHvDdsjbABySIjaa73aqItlKGk7+NN8pYmlqLVHxHdJSg/dJ40hosBPXtGE8xmLXxnJWjIe0RyjywRLH4IXUHhySlgfhNI7BTomadiOkR/JBu9kTlkWmBQ61LgK1WEURodvNhxs4zuU+teI6HwUHDc/VnzbF/8te0S3F/zybeke4ZPlh7T9JJa8gqxn1SpddxzZF3+691GZw2OouZM16CAtzqbr0u7L40jvB1TY+4h+1EzCGEoFDCgKEuQSMX3ofeI/2HqOurvyQ8rbgnWR6DwzNwSVpczBPARg0FWBpNy7azQHt5muYFakdENQyDLxyzUZkY3Uf8uB83sOlO2b91cs3m5Hly14Kz6w/06ZifW0j18OWZ4gFjyqW3HHWnIOwcEWx0bSvZPEcvaYkeA0WrzjPG+HqStEe83kG5qDqf03tfhizskLAtt0dxU31n68HYyJV/CHscY0csETQySF1O4+k1c45jaDzU6KlvbhoPwe0l69hVWR2IFCrMNCKFRtxub0cuIHgTNo345z4sNX59q+bav+Ff4qYeX+mTcX7jGP9dO866NGlgkeQccBDVexzni+6Nm1+bj9GOKeKei42UfC6yc919aMoX7BRfQy6xS/tbiJr78Wj23Vu0+CDN84R6/4ewlNEPfYuU3QXmp0/0mTnmvLeaSlw0l5AtBs77aWp2xT57N5V5jtQuUg9IrGaD9f9bJo300/0NN/+++rln682RP+SP3gtND/LomL5uFRQNBd3DYM+EFamqlt8RtdJKW07fA7WleJ1gw9hSZ50f89RXFUIMTrlSFF398yWXGLd3EPYfk3c9vackQKXdWsPYY9r5CBLBJ0cUrfTSFrtjNMIOjklWtqLi/ZzQHv5GlZFZgcCtQoDrVixEZffy4G4jDqT9vDplk/nXV6++2fbA28vvn/wu8GX/el16XTOs6n2Qmz/Z2CzEVaZ4FXM2E7oSVW9hbCkwJvOPhYbPZOie6yYMGrQfT2EdbsBEqDiWNJNffKY8YLegQnrUDlsWnpIObUsSPpDWPW6rxJF/K7VeSSNdc4pv52eAiHthUI7MdNecrpFkcXuW+W7w5RL06PpK7hd57OJDrPh95L8lSb59D+yzULiCmVuZHN0cmVhbQplbmRvYmoKMTIgMCBvYmoKMjIxNAplbmRvYmoKMTAgMCBvYmoKWyBdCmVuZG9iagoxOCAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDkxID4+CnN0cmVhbQp4nDWMuw3AMAhEe6a4Efg4gPeJohT2/m2ILRfcPemJ82xgZJ2HI7TjFrKmcFNMUk6odwxqpTcdO+glzf00yXouGvQPcfUVtpsDklEkkYdEl8uVZ+VffD4MbxxiCmVuZHN0cmVhbQplbmRvYmoKMTkgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAyMzUgPj4Kc3RyZWFtCnicNVFJbgAxCLvnFf5ApbAn75mq6qH9/7WGUS8DA9jYJO/BRiQ+xJDuKFd8yuo0y/A7WeTFz0rh5L2ICqQqwgppB89yVjMMnhuZApcz8VlmPpkWOxZQTcRxduQ0g0GIaVxHy+kw0zzoCbk+GHFjp1muYkjr3VK9vtfynyrKR9bdLLdO2dRK3aJn7Elcdl5PbWlfGHUUNwWRDh87vAf5IuYsLjqRbvabKYeVpCE4LYAfiaFUzw6vESZ+ZiR4yp5O76M0vPZB0/W9e0FHbiZkKrdQRiqerDTGjKH6jWgmqe//gZ71vb7+AENNVLkKZW5kc3RyZWFtCmVuZG9iagoyMCAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDE2NCA+PgpzdHJlYW0KeJw9kMERQyEIRO9WsSWAgEA9yWRy+L//a0CTXGQdYPepO4GQUYczw2fiyYPTsTRwbxWMawivI/QITQKTwMTBmngMCwGnYZFjLt9VllWnla6ajZ7XvWNB1WmXNQ1t2oHyrY8/wjXeo/Aa7B5CB7EodG5lWguZWDxrnDvMo8znfk7bdz0YrabUrDdy2dc9OsvUUF5a+4TOaLT9J9cvuzFeH4UUOQgKZW5kc3RyZWFtCmVuZG9iagoyMSAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDc2ID4+CnN0cmVhbQp4nDM1N1UwULC0ABKmhuYK5kaWCimGXEA+iJXLBRPLAbPMTMyALENLZJaJsSGQZWJhhsQyNrGAyiJYBkAabE0OzPQcrgyuNAA1FxkFCmVuZHN0cmVhbQplbmRvYmoKMjIgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAyNDcgPj4Kc3RyZWFtCnicTVFJbsQwDLv7FfzAAJasxXlPikEP7f+vJR0U7cEQI0tc4u7ERBZetlDXQofjw0ZeCZuB74PWnPgaseI/2kaklT9UWyATMVEkdFE3GvdIN7wK0X6kgleq91jzEXcrzVs6drG/98G05pEqq0I85Ngc2Uha10TR8T203nNDdMoggT43IQdEaY5ehaS/9sN1bTS7tTazJ6qDR6aE8kmzGprTKWbIbKjHbSpWMgo3qoyK+1RGWg/yNs4ygJPjhDJaT3asJqL81CeXkBcTccIuOzsWYhMLG4e0H5U+sfx86834m2mtpZBxQSI0xaXfZ7zH53j/AJVPXCYKZW5kc3RyZWFtCmVuZG9iagoyMyAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDUxID4+CnN0cmVhbQp4nDOyNFUwULC0ABKGluYK5kaWCimGXEA+iJXLBRPLAbMMgDRYaQ5MRQ5XBlcaAL+MDVYKZW5kc3RyZWFtCmVuZG9iagoyNCAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDg0ID4+CnN0cmVhbQp4nDWNQRLAMARF907hCCFB3KfT6ULvvy1JuuF5g6+i2NBnFjVDY8eLIOeiF8i3i0WDKUl4HKdCh3g69rlcfmm1NXavuy50qMwKiz8j4IH7A9A7GiwKZW5kc3RyZWFtCmVuZG9iagoyNSAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDYxID4+CnN0cmVhbQp4nDM1NVcwULC0ABKmpkYK5kaWCimGXEA+iJXLZWhpDmblgFkWxkAGSBmcYQCkwZpzYHpyuDK40gDLFRDMCmVuZHN0cmVhbQplbmRvYmoKMjYgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCA5MCA+PgpzdHJlYW0KeJw9jssNwDAIQ+9MwQjhUwL7VFUPyf7Xhnx6wQ9byLgJFgwfo9qFlQNvgrEndWBdXgMVQhYZZOTbOxeLSmYWv5omqRPSJHHeRKE7TUqdD7TT2+CF5wP16R3sCmVuZHN0cmVhbQplbmRvYmoKMjcgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAyNTUgPj4Kc3RyZWFtCnicNVFLbkQxCNvnFFxgpED4JOeZatRFe/9tbdK3CRYfY5PaJVMi5aW2pZZKucmXjnVcMk1+xzJrZBmSK8RsSWyT99CtEhjTnOLgYFzprABZmbBDz+kZ9USFLMfkksrdgrSTPMFmrAZIbnvObIK0akLGu4KIS9lBEZy5skhCoZfT5LHyHt8jFkQtuGKiPf+M8PVAx9hLlci8kWvfBnF2hNTpjRZkvcBFekZ4O9rIJhzDuG/ZB/kND1G8sjmF/jsA8DqCatTtzsV2jteE33N/gwsYsfpko6jqDvbfmZqzWfiDJGW8W4iMGXUIw732fG6Ll8tB6vjIexke6fMHDuBj0gplbmRzdHJlYW0KZW5kb2JqCjI4IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMzQxID4+CnN0cmVhbQp4nDVSO9KbQQjrv1PoAp5Z3st5nMmk+HP/NgI7FSywQgLSAgeZeIkhqlGu+CVPMF4n8He9PI2fx7uQWvBUpB+4Nm3j/VizJgqWRiyF2ce+HyXkeGr8GwI9F2nCjExGDiQDcb/W5896kymH34A0bU4fJUkPogW7W8OOLwsySHpSw5Kd/LCuBVYXoQlzY00kI6dWpub52DNcxhNjJKiaBSTpE/epghFpxmPnrCUPMhxP9eLFr7fxWuYx9bKqQMY2wRxsJzPhFEUE4heUJDdxF00dxdHMWHO70FBS5L67h5OTXveXk6jAKyGcxVrCMUNPWeZkp0EJVK2cADOs174wTtNGCXdqur0r9vXzzCSM2xx2VkqmwTkO7mWTOYJkrzsmbMLjEPPePYKRmDe/iy2CK5c512T6sR9FG+mD4vqcqymzFSX8Q5U8seIa/5/f+/nz/P4HjCh+IwplbmRzdHJlYW0KZW5kb2JqCjI5IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggNjYgPj4Kc3RyZWFtCnicMzM0VDBQ0DUCEmaGJgrmRpYKKYZcQD6IlcsFE8sBs8xMzIAsY1NTJJYBkDYyNYPTEBmgAXAGRH8GVxoAUmsUwAplbmRzdHJlYW0KZW5kb2JqCjMwIDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMzA3ID4+CnN0cmVhbQp4nD2SS24DMQxD9z6FLhDA+tme86Qoupjef9snJemKHNkWRWqWukxZUx6QNJOEf+nwcLGd8jtsz2Zm4Fqil4nllOfQFWLuonzZzEZdWSfF6oRmOrfoUTkXBzZNqp+rLKXdLngO1yaeW/YRP7zQoB7UNS4JN3RXo2UpNGOq+3/Se/yMMuBqTF1sUqt7HzxeRFXo6AdHiSJjlxfn40EJ6UrCaFqIlXdFA0Hu8rTKewnu295qyLIHqZjOOylmsOt0Ui5uF4chHsjyqPDlo9hrQs/4sCsl9EjYhjNyJ+5oxubUyOKQ/t6NBEuPrmgh8+CvbtYuYLxTOkViZE5yrGmLVU73UBTTucO9DBD1bEVDKXOR1epfw84La5ZsFnhK+gUeo90mSw5W2duoTu+tPNnQ9x9a13QfCmVuZHN0cmVhbQplbmRvYmoKMzEgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCA2NDMgPj4Kc3RyZWFtCnicTZRBrmUpDEPnbxXZwJUICQHW81ulHlTvf1rHua+kHhFBSBzb4GMMG1Zlj++wG8P2SPvHP7GnzZr23xv5sjhhvo/lKPM17eeT85rPsiw397A1Zq8/n5VvtCiqjHV1Ryfl3NnXKpyq9a6laopiHFNGZPad2K5qIIi7baVbutPnXUFQb5QAV0aO/b0jtKoi9Kr6d56fz790OqArZis/dr1bbaF1ujf8ZXltkZNhSamMnncriEOaqjMTZNELBE6vedMcFFrfXoqCW8qIM/pOzhefN29d88y3ydGd7krUIPZqVFnNKjBzCSMqxDTNkcz20xMlE/7+7PH/SBoQrYUKSHtRBWVOa6B7BzzT004NEHuvwSknilDsLCY4ZYf50rdOgig3VdQJ4u5p5X8+u1CNvD1Bv7fVTisMBr65rHpXqMnCT1rhdL9RBl6Ymmf0fDDEzCU9cdlCpKk+re0E9Qp4xokpzuXKVB9HNaH1WM271llLJ4pgQzo5O17RnHCCEgCdMgkL59qd1HwClZn5WRyh58O0IAbTQ9eE1ceHbL/fQMa53707SJK9WVvW2kR1TLI80LcR4mkrbAA/0IBQ2SU5xOGP8yAKCR7P1njoUBSv73N9G++2Zn7DUGMHbISysvkCwOPIOiHhOdjiUrWLOnZ6TjOBhWD4vkLCU+lbmMyipTkkiIm8u718L6JJQmeKVFU+hUUHh5zVVE2JCoHzYARJEzz893mSU6BI7ujHWZhw92NaPARFxUR1LrGANE8lq2BJzLOurLn6S8CSfChrXDtXlkyetL4EmfVOUXL7Zwuq9NqsKxIfd8gQ2Hnpy+pHIQsi1NSA7yPz7xvTr/GbH+TXHzPv+SsKZW5kc3RyZWFtCmVuZG9iagozMiAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDIzMiA+PgpzdHJlYW0KeJw1UUluxDAMu/sV/MAA1u68J8Wgh/b/11LKFAhAJba4JWJjIwIvMfg5iNz4kjWjJn5nclf8LE+FR8Kt4EkUgZfhXnaCyxvGZT8OMx+8l1bOpMaTDMhFNj08ETLYJRA6MLsGddhm2om+IeGzI1LNRpbT1xL00ioEylO23+mCEm2r+nP7rAtt+9oTTnZ76knlE4jnlqzAZeMVk8VYBj1RuUsxfZDqbKEnobwon4NsPmqIRJcoZ+CJwcEo0A7sue1n4lUhaF3dp21jqEZKx9O/DU1Nkgj5RAlntjTuFv5/z72+1/sPTiFUEQplbmRzdHJlYW0KZW5kb2JqCjMzIDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMjMxID4+CnN0cmVhbQp4nDVPOZIEIQzLeYU+MFUY20C/p6e2Ntj5f7qSmU6Q8CHJ0xMdmXiZIyOwZsfbWmQgZuBTTMW/9rQPE6r34B4ilIsLYYaRcNas426ejhf/dpXPWAfvNviKWV4Q2MJM1lcWZy7bBWNpnMQ5yW6MXROxjXWtp1NYRzChDIR0tsOUIHNUpPTJjjLm6DiRJ56L7/bbLHY5fg7rCzaNIRXn+Cp6gjaDoux57wIackH/Xd34HkW76CUgGwkW1lFi7pzlhF+9dnQetSgSc0KaQS4TIc3pKqYQmlCss6OgUlFwqT6n6Kyff+VfXC0KZW5kc3RyZWFtCmVuZG9iagozNCAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDI0OSA+PgpzdHJlYW0KeJw9UDuORCEM6zmFL/Ak8iNwHkarLWbv364DmilQTH62MyTQEYFHDDGUr+MlraCugb+LQvFu4uuDwiCrQ1IgznoPiHTspjaREzodnDM/YTdjjsBFMQac6XSmPQcmOfvCCoRzG2XsVkgniaoijuozjimeKnufeBYs7cg2WyeSPeQg4VJSicmln5TKP23KlAo6ZtEELBK54GQTTTjLu0lSjBmUMuoepnYifaw8yKM66GRNzqwjmdnTT9uZ+Bxwt1/aZE6Vx3QezPictM6DORW69+OJNgdNjdro7PcTaSovUrsdWp1+dRKV3RjnGBKXZ38Z32T/+Qf+h1oiCmVuZHN0cmVhbQplbmRvYmoKMzUgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAzOTUgPj4Kc3RyZWFtCnicPVJLbsVACNvnFFyg0vCbz3lSVd28+29rQ1KpKryJMcYwfcqQueVLXRJxhcm3Xq5bPKZ8LltamXmIu4uNJT623JfuIbZddC6xOB1H8gsynSpEqM2q0aH4QpaFB5BO8KELwn05/uMvgMHXsA244T0yQbAk5ilCxm5RGZoSQRFh55EVqKRQn1nC31Hu6/cyBWpvjKULYxz0CbQFQm1IxALqQABE7JRUrZCOZyQTvxXdZ2IcYOfRsgGuGVRElnvsx4ipzqiMvETEPk9N+iiWTC1Wxm5TGV/8lIzUfHQFKqk08pTy0FWz0AtYiXkS9jn8SPjn1mwhhjpu1vKJ5R8zxTISzmBLOWChl+NH4NtZdRGuHbm4znSBH5XWcEy0637I9U/+dNtazXW8cgiiQOVNQfC7Dq5GscTEMj6djSl6oiywGpq8RjPBYRAR1vfDyAMa/XK8EDSnayK0WCKbtWJEjYpscz29BNZM78U51sMTwmzvndahsjMzKiGC2rqGautAdrO+83C2nz8z6KJtCmVuZHN0cmVhbQplbmRvYmoKMzYgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCA5NCA+PgpzdHJlYW0KeJxFjcERwCAIBP9UQQkKCtpPJpOH9v+NEDJ8YOcO7oQFC7Z5Rh8FlSZeFVgHSmPcUI9AveFyLcncBQ9wJ3/a0FScltN3aZFJVSncpBJ5/w5nJpCoedFjnfcLY/sjPAplbmRzdHJlYW0KZW5kb2JqCjM3IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMTY0ID4+CnN0cmVhbQp4nEWQx3EFMQxD76oCJTCACvWsx/MP6/6vhvTTQXoYQgxiT8KwXFdxYXTDj7ctMw1/RxnuxvoyY7zVWCAn6AMMkYmr0aT6dsUZqvTk1WKuo6JcLzoiEsyS46tAI3w6sseTtrYz/XReH+wh7xP/KirnbmEBLqruQPlSH/HUj9lR6pqhjyorax5q2leEXRFK2z4upzJO3b0DWuG9las92u8/HnY68gplbmRzdHJlYW0KZW5kb2JqCjM4IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggNzIgPj4Kc3RyZWFtCnicMzK3UDBQsDQBEoYWJgrmZgYKKYZcQL6piblCLhdIDMTKAbMMgLQlnIKIZ4CYIG0QxSAWRLGZiRlEHZwBkcvgSgMAJdsWyQplbmRzdHJlYW0KZW5kb2JqCjM5IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMjU4ID4+CnN0cmVhbQp4nEWRS3IEIAhE956CI4D85DyTSmUxuf82Dc5kNnaXqP2ESiOmEiznFHkwfcnyzWS26Xc5VjsbBRRFKJjJVeixAqs7U8SZa4lq62Nl5LjTOwbFG85dOalkcaOMdVR1KnBMz5X1Ud35dlmUfUcOZQrYrHMcbODKbcMYJ0abre4O94kgTydTR8XtINnwByeNfZWrK3CdbPbRSzAOBP1CE5jki0DrDIHGzVP05BLs4+N254Fgb3kRSNkQyJEhGB2Cdp1c/+LW+b3/cYY7z7UZrhzv4neY1nbHX2KSFXMBi9wpqOdrLlrXGTrekzPH5Kb7hs65YJe7g0zv+T/Wz/r+Ax4pZvoKZW5kc3RyZWFtCmVuZG9iago0MCAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDkzID4+CnN0cmVhbQp4nDWNuw3AMAhEe6ZgBDDGmH2iKIWzfxswTnd695sykZDFUBiNGNUHXgxbBn2h2wxPcG3mFGJ0yfiCzo5NNRS7FsqpHZJBp5cotyqVB9UUa2es2P+54IH7A8L5HZgKZW5kc3RyZWFtCmVuZG9iago0MSAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDMyMiA+PgpzdHJlYW0KeJw1UbttxTAM7DUFFzAgfiXN4yBIkbd/mzvaqUjTvB9VXjKlXC51ySpZYfKlQ3WKpnyeZqb8DvWQ45ge2SG6U9aWexgWlol5Sh2xmiz3cAs2vgCaEnML8fcI8CuAUcBEoG7x9w+6WRJAGhT8FOiaq5ZYYgINi4Wt2RXiVt0pWLir+HYkuQcJcjFZ6FMORYopt8B8GSzZkVqc63JZCv9ufQIaYYU47LOLROB5wANMJP5kgGzPPlvs6upFNnaGOOnQgIuAm80kAUFTOKs+uGH7arvm55koJzg51q+iMb4NTuZLUt5XucfPoEHe+DM8Z3eOUA6aUAj03QIgh93ARoQ+tc/ALgO2Sbt3Y0r5nGQpvgQ2CvaoUx3K8GLszFZv2PzH6MpmUWyQlfXR6Q7K3KATYh5vZKFbsrb7Nw+zff8BXxl7ZAplbmRzdHJlYW0KZW5kb2JqCjQyIDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMjE4ID4+CnN0cmVhbQp4nD1QuY0EMQzLXYUaWMB67alnFotLpv/0SPn2ItEWRVIqNZmSKS91lCVZU946fJbEDnmG5W5kNiUqRS+TsCX30ArxfYnmFPfd1ZazQzSXaDl+CzMqqhsd00s2mnAqE7qg3MMz+g1tdANWhx6xWyDQpGDXtiByxw8YDMGZE4siDEpNBv+uco+fXosbPsPxQxSRkg7mNf9Y/fJzDa9TjyeRbm++4l6cqQ4DERySmrwjXVixLhIRaTVBTc/AWi2Au7de/hu0I7oMQPaJxHGaUo6hv2twpc8v5SdT2AplbmRzdHJlYW0KZW5kb2JqCjQzIDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggODMgPj4Kc3RyZWFtCnicRYy7DcAwCER7pmAEfib2PlGUwt6/DRAlbrgn3T1cHQmZKW4zw0MGngwshl1xgfSWMAtcR1COneyjYdW+6gSN9aZS8+8PlJ7srOKG6wECQhpmCmVuZHN0cmVhbQplbmRvYmoKNDQgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAxNTAgPj4Kc3RyZWFtCnicPU85DsMwDNv9Cn4ggHVYtt6TIuiQ/n+t6KAdBBGgeMiyo2MFDjGBSccciZe0H/w0jUAsg5ojekLFMCxwNkmBh0FWSVc+W5xMIbUFXkj41hQ8G01kgp7HiB24k8noA+9SW7F16AHtEFUkXbMMY7GtunA9YQQ1xXoV5vUwY4mSR59VS+sBBRP40vl/7m7vdn0BYMUwXQplbmRzdHJlYW0KZW5kb2JqCjQ1IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMTUxID4+CnN0cmVhbQp4nDWPyw3DMAxD75qCCwTQz7I8T4qgh3T/ayWnBQyYMMkn2RaDkYxDTGDsmGPhJVRPrT4kI7e6STkQqVA3BE9oTAwznKRL4JXpvmU8t3g5rdQFnZDI3VltNEQZzTyGo6fsFU76L3OTqJUZZQ7IrFPdTsjKghWYF9Ry38+4rXKhEx62K8OiO8WIcpsZafj976Q3XV/ceDDVCmVuZHN0cmVhbQplbmRvYmoKNDYgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAzMjAgPj4Kc3RyZWFtCnicNVJLbgUxCNvPKbhApfBPzvOqqou++29rE70VTDBg4ykvWdJLvtQl26XD5Fsf9yWxQt6P7ZrMUsX3FrMUzy2vR88Rty0KBFETPViZLxUi1M/06DqocEqfgVcItxQbvINJAINq+AcepTMgUOdAxrtiMlIDgiTYc2lxCIlyJol/pLye3yetpKH0PVmZy9+TS6XQHU1O6AHFysVJoF1J+aCZmEpEkpfrfbFC9IbAkjw+RzHJgOw2iW2iBSbnHqUlzMQUOrDHArxmmtVV6GDCHocpjFcLs6gebPJbE5WkHa3jGdkw3sswU2Kh4bAF1OZiZYLu5eM1r8KI7VGTXcNw7pbNdwjRaP4bFsrgYxWSgEensRINaTjAiMCeXjjFXvMTOQ7AiGOdmiwMY2gmp3qOicDQnrOlYcbHHlr18w9U6XyHCmVuZHN0cmVhbQplbmRvYmoKNDcgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAxMzMgPj4Kc3RyZWFtCnicRY9LDgQhCET3nKKOwMcf53Ey6YVz/+2AnW4TYz2FVIG5gqE9LmsDnRUfIRm28beplo5FWT5UelJWD8ngh6zGyyHcoCzwgkkqhiFQi5gakS1lbreA2zYNsrKVU6WOsIujMI/2tGwVHl+iWyJ1kj+DxCov3OO6Hcil1rveoou+f6QBMQkKZW5kc3RyZWFtCmVuZG9iago0OCAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDM0MCA+PgpzdHJlYW0KeJw1UjluBDEM6/0KfSCAbtvv2SBIkfy/DanZFANxdFKUO1pUdsuHhVS17HT5tJXaEjfkd2WFxAnJqxLtUoZIqLxWIdXvmTKvtzVnBMhSpcLkpORxyYI/w6WnC8f5trGv5cgdjx5YFSOhRMAyxcToGpbO7rBmW36WacCPeIScK9Ytx1gFUhvdOO2K96F5LbIGiL2ZlooKHVaJFn5B8aBHjX32GFRYINHtHElwjIlQkYB2gdpIDDl7LHZRH/QzKDET6NobRdxBgSWSmDnFunT03/jQsaD+2Iw3vzoq6VtaWWPSPhvtlMYsMul6WPR089bHgws076L859UMEjRljZLGB63aOYaimVFWeLdDkw3NMcch8w6ewxkJSvo8FL+PJRMdlMjfDg2hf18eo4ycNt4C5qI/bRUHDuKzw165gRVKF2uS9wGpTOiB6f+v8bW+19cfHe2AxgplbmRzdHJlYW0KZW5kb2JqCjQ5IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMjUxID4+CnN0cmVhbQp4nC1RSXIDQQi7zyv0hGan32OXK4fk/9cIygcGDYtAdFrioIyfICxXvOWRq2jD3zMxgt8Fh34r121Y5EBUIEljUDWhdvF69B7YcZgJzJPWsAxmrA/8jCnc6MXhMRlnt9dl1BDsXa89mUHJrFzEJRMXTNVhI2cOP5kyLrRzPTcg50ZYl2GQblYaMxKONIVIIYWqm6TOBEESjK5GjTZyFPulL490hlWNqDHscy1tX89NOGvQ7Fis8uSUHl1xLicXL6wc9PU2AxdRaazyQEjA/W4P9XOyk994S+fOFtPje83J8sJUYMWb125ANtXi37yI4/uMr+fn+fwDX2BbiAplbmRzdHJlYW0KZW5kb2JqCjUwIDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMTc0ID4+CnN0cmVhbQp4nE2QSQ5DIQxD95zCF6iEM8DnPL+qumjvv61DB3WB/OQgcDw80HEkLnRk6IyOK5sc48CzIGPi0Tj/ybg+xDFB3aItWJd2x9nMEnPCMjECtkbJ2TyiwA/HXAgSZJcfvsAgIl2P+VbzWZP0z7c73Y+6tGZfPaLAiewIxbABV4D9useBS8L5XtPklyolYxOH8oHqIlI2O6EQtVTscqqKs92bK3AV9PzRQ+7tBbUjPN8KZW5kc3RyZWFtCmVuZG9iago1MSAwIG9iago8PCAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDIxNSA+PgpzdHJlYW0KeJw1UTkOAyEM7PcV/kAkjC94T6Iozf6/zYzRVh7BXIa0lCGZ8lKTqCHlUz56mS6cutzXzGo055a0LXOAuLa8L62SwIlmiIPBaZi4AZo8AUPX0ahRQxce0NSlUyiw3AQ+irduD91jtYGXtiHniSBiKBksQc2pRRMWbc8npDW/Xosb3pft3chTpcaWGIEGAVY4HNfo1/CVPU8m0XQVMtSrNcsYCRNFIjz5jqbVE+taNNIyEtTGEaxqA7w7/TBOAAATccsCZJ9KlLPkxG+x9LMGV/r+AZ9HVJYKZW5kc3RyZWFtCmVuZG9iagoxNiAwIG9iago8PCAvQmFzZUZvbnQgL0RlamFWdVNhbnMgL0NoYXJQcm9jcyAxNyAwIFIKL0VuY29kaW5nIDw8Ci9EaWZmZXJlbmNlcyBbIDQwIC9wYXJlbmxlZnQgL3BhcmVucmlnaHQgNDggL3plcm8gL29uZSAvdHdvIC90aHJlZSAvZm91ciA1NCAvc2l4IDU2Ci9laWdodCAvbmluZSA2NCAvYXQgL0EgNjcgL0MgL0QgNzAgL0YgL0cgNzMgL0kgNzUgL0sgL0wgL00gODEgL1EgODMgL1MgL1QKOTcgL2EgOTkgL2MgL2QgL2UgMTA0IC9oIC9pIDEwOSAvbSAxMTEgL28gMTE2IC90IC91IDIxNSAvbXVsdGlwbHkgXQovVHlwZSAvRW5jb2RpbmcgPj4KL0ZpcnN0Q2hhciAwIC9Gb250QkJveCBbIC0xMDIxIC00NjMgMTc5NCAxMjMzIF0gL0ZvbnREZXNjcmlwdG9yIDE1IDAgUgovRm9udE1hdHJpeCBbIDAuMDAxIDAgMCAwLjAwMSAwIDAgXSAvTGFzdENoYXIgMjU1IC9OYW1lIC9EZWphVnVTYW5zCi9TdWJ0eXBlIC9UeXBlMyAvVHlwZSAvRm9udCAvV2lkdGhzIDE0IDAgUiA+PgplbmRvYmoKMTUgMCBvYmoKPDwgL0FzY2VudCA5MjkgL0NhcEhlaWdodCAwIC9EZXNjZW50IC0yMzYgL0ZsYWdzIDMyCi9Gb250QkJveCBbIC0xMDIxIC00NjMgMTc5NCAxMjMzIF0gL0ZvbnROYW1lIC9EZWphVnVTYW5zIC9JdGFsaWNBbmdsZSAwCi9NYXhXaWR0aCAxMzQyIC9TdGVtViAwIC9UeXBlIC9Gb250RGVzY3JpcHRvciAvWEhlaWdodCAwID4+CmVuZG9iagoxNCAwIG9iagpbIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwCjYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgMzE4IDQwMSA0NjAgODM4IDYzNgo5NTAgNzgwIDI3NSAzOTAgMzkwIDUwMCA4MzggMzE4IDM2MSAzMTggMzM3IDYzNiA2MzYgNjM2IDYzNiA2MzYgNjM2IDYzNiA2MzYKNjM2IDYzNiAzMzcgMzM3IDgzOCA4MzggODM4IDUzMSAxMDAwIDY4NCA2ODYgNjk4IDc3MCA2MzIgNTc1IDc3NSA3NTIgMjk1CjI5NSA2NTYgNTU3IDg2MyA3NDggNzg3IDYwMyA3ODcgNjk1IDYzNSA2MTEgNzMyIDY4NCA5ODkgNjg1IDYxMSA2ODUgMzkwIDMzNwozOTAgODM4IDUwMCA1MDAgNjEzIDYzNSA1NTAgNjM1IDYxNSAzNTIgNjM1IDYzNCAyNzggMjc4IDU3OSAyNzggOTc0IDYzNCA2MTIKNjM1IDYzNSA0MTEgNTIxIDM5MiA2MzQgNTkyIDgxOCA1OTIgNTkyIDUyNSA2MzYgMzM3IDYzNiA4MzggNjAwIDYzNiA2MDAgMzE4CjM1MiA1MTggMTAwMCA1MDAgNTAwIDUwMCAxMzQyIDYzNSA0MDAgMTA3MCA2MDAgNjg1IDYwMCA2MDAgMzE4IDMxOCA1MTggNTE4CjU5MCA1MDAgMTAwMCA1MDAgMTAwMCA1MjEgNDAwIDEwMjMgNjAwIDUyNSA2MTEgMzE4IDQwMSA2MzYgNjM2IDYzNiA2MzYgMzM3CjUwMCA1MDAgMTAwMCA0NzEgNjEyIDgzOCAzNjEgMTAwMCA1MDAgNTAwIDgzOCA0MDEgNDAxIDUwMCA2MzYgNjM2IDMxOCA1MDAKNDAxIDQ3MSA2MTIgOTY5IDk2OSA5NjkgNTMxIDY4NCA2ODQgNjg0IDY4NCA2ODQgNjg0IDk3NCA2OTggNjMyIDYzMiA2MzIgNjMyCjI5NSAyOTUgMjk1IDI5NSA3NzUgNzQ4IDc4NyA3ODcgNzg3IDc4NyA3ODcgODM4IDc4NyA3MzIgNzMyIDczMiA3MzIgNjExIDYwNQo2MzAgNjEzIDYxMyA2MTMgNjEzIDYxMyA2MTMgOTgyIDU1MCA2MTUgNjE1IDYxNSA2MTUgMjc4IDI3OCAyNzggMjc4IDYxMiA2MzQKNjEyIDYxMiA2MTIgNjEyIDYxMiA4MzggNjEyIDYzNCA2MzQgNjM0IDYzNCA1OTIgNjM1IDU5MiBdCmVuZG9iagoxNyAwIG9iago8PCAvQSAxOCAwIFIgL0MgMTkgMCBSIC9EIDIwIDAgUiAvRiAyMSAwIFIgL0cgMjIgMCBSIC9JIDIzIDAgUiAvSyAyNCAwIFIKL0wgMjUgMCBSIC9NIDI2IDAgUiAvUSAyNyAwIFIgL1MgMjggMCBSIC9UIDI5IDAgUiAvYSAzMCAwIFIgL2F0IDMxIDAgUgovYyAzMiAwIFIgL2QgMzMgMCBSIC9lIDM0IDAgUiAvZWlnaHQgMzUgMCBSIC9mb3VyIDM2IDAgUiAvaCAzNyAwIFIKL2kgMzggMCBSIC9tIDM5IDAgUiAvbXVsdGlwbHkgNDAgMCBSIC9uaW5lIDQxIDAgUiAvbyA0MiAwIFIgL29uZSA0MyAwIFIKL3BhcmVubGVmdCA0NCAwIFIgL3BhcmVucmlnaHQgNDUgMCBSIC9zaXggNDYgMCBSIC90IDQ3IDAgUiAvdGhyZWUgNDggMCBSCi90d28gNDkgMCBSIC91IDUwIDAgUiAvemVybyA1MSAwIFIgPj4KZW5kb2JqCjMgMCBvYmoKPDwgL0YxIDE2IDAgUiA+PgplbmRvYmoKNCAwIG9iago8PCAvQTEgPDwgL0NBIDAgL1R5cGUgL0V4dEdTdGF0ZSAvY2EgMSA+PgovQTIgPDwgL0NBIDEgL1R5cGUgL0V4dEdTdGF0ZSAvY2EgMSA+PgovQTMgPDwgL0NBIDAuOCAvVHlwZSAvRXh0R1N0YXRlIC9jYSAwLjggPj4gPj4KZW5kb2JqCjUgMCBvYmoKPDwgPj4KZW5kb2JqCjYgMCBvYmoKPDwgPj4KZW5kb2JqCjcgMCBvYmoKPDwgL1AwIDEzIDAgUiA+PgplbmRvYmoKMTMgMCBvYmoKPDwgL0JCb3ggWyAtMy40OCAtMy40OCAzLjQ4IDMuNDggXSAvRmlsdGVyIC9GbGF0ZURlY29kZSAvTGVuZ3RoIDEzMQovU3VidHlwZSAvRm9ybSAvVHlwZSAvWE9iamVjdCA+PgpzdHJlYW0KeJxtkEEOhCAMRfc9RS/wSUtFZevSa7iZTOL9twNxQEzdNNC+PH5R/pLwTqXA+CQJS06z5HrTkNK6TIwY5tWyKMegUS3WznU4qM/QcGN0i7EUptTW6Hijm+k23pM/+rBZIUY/HA6vhHsWQyZcKTEGh98LL9vD/xGeXtTAH6KNfmNaQ/0KZW5kc3RyZWFtCmVuZG9iagoyIDAgb2JqCjw8IC9Db3VudCAxIC9LaWRzIFsgMTEgMCBSIF0gL1R5cGUgL1BhZ2VzID4+CmVuZG9iago1MiAwIG9iago8PCAvQ3JlYXRpb25EYXRlIChEOjIwMjIxMTA0MTQzMjM0WikKL0NyZWF0b3IgKE1hdHBsb3RsaWIgdjMuNC4xLCBodHRwczovL21hdHBsb3RsaWIub3JnKQovUHJvZHVjZXIgKE1hdHBsb3RsaWIgcGRmIGJhY2tlbmQgdjMuNC4xKSA+PgplbmRvYmoKeHJlZgowIDUzCjAwMDAwMDAwMDAgNjU1MzUgZiAKMDAwMDAwMDAxNiAwMDAwMCBuIAowMDAwMDE0NzM4IDAwMDAwIG4gCjAwMDAwMTQyMjQgMDAwMDAgbiAKMDAwMDAxNDI1NiAwMDAwMCBuIAowMDAwMDE0Mzk4IDAwMDAwIG4gCjAwMDAwMTQ0MTkgMDAwMDAgbiAKMDAwMDAxNDQ0MCAwMDAwMCBuIAowMDAwMDAwMDY1IDAwMDAwIG4gCjAwMDAwMDA0MDIgMDAwMDAgbiAKMDAwMDAwMjcxMiAwMDAwMCBuIAowMDAwMDAwMjA4IDAwMDAwIG4gCjAwMDAwMDI2OTEgMDAwMDAgbiAKMDAwMDAxNDQ3MiAwMDAwMCBuIAowMDAwMDEyNzYxIDAwMDAwIG4gCjAwMDAwMTI1NjEgMDAwMDAgbiAKMDAwMDAxMjA1OSAwMDAwMCBuIAowMDAwMDEzODE0IDAwMDAwIG4gCjAwMDAwMDI3MzIgMDAwMDAgbiAKMDAwMDAwMjg5NSAwMDAwMCBuIAowMDAwMDAzMjAzIDAwMDAwIG4gCjAwMDAwMDM0NDAgMDAwMDAgbiAKMDAwMDAwMzU4OCAwMDAwMCBuIAowMDAwMDAzOTA4IDAwMDAwIG4gCjAwMDAwMDQwMzEgMDAwMDAgbiAKMDAwMDAwNDE4NyAwMDAwMCBuIAowMDAwMDA0MzIwIDAwMDAwIG4gCjAwMDAwMDQ0ODIgMDAwMDAgbiAKMDAwMDAwNDgxMCAwMDAwMCBuIAowMDAwMDA1MjI0IDAwMDAwIG4gCjAwMDAwMDUzNjIgMDAwMDAgbiAKMDAwMDAwNTc0MiAwMDAwMCBuIAowMDAwMDA2NDU4IDAwMDAwIG4gCjAwMDAwMDY3NjMgMDAwMDAgbiAKMDAwMDAwNzA2NyAwMDAwMCBuIAowMDAwMDA3Mzg5IDAwMDAwIG4gCjAwMDAwMDc4NTcgMDAwMDAgbiAKMDAwMDAwODAyMyAwMDAwMCBuIAowMDAwMDA4MjYwIDAwMDAwIG4gCjAwMDAwMDg0MDQgMDAwMDAgbiAKMDAwMDAwODczNSAwMDAwMCBuIAowMDAwMDA4OTAwIDAwMDAwIG4gCjAwMDAwMDkyOTUgMDAwMDAgbiAKMDAwMDAwOTU4NiAwMDAwMCBuIAowMDAwMDA5NzQxIDAwMDAwIG4gCjAwMDAwMDk5NjQgMDAwMDAgbiAKMDAwMDAxMDE4OCAwMDAwMCBuIAowMDAwMDEwNTgxIDAwMDAwIG4gCjAwMDAwMTA3ODcgMDAwMDAgbiAKMDAwMDAxMTIwMCAwMDAwMCBuIAowMDAwMDExNTI0IDAwMDAwIG4gCjAwMDAwMTE3NzEgMDAwMDAgbiAKMDAwMDAxNDc5OCAwMDAwMCBuIAp0cmFpbGVyCjw8IC9JbmZvIDUyIDAgUiAvUm9vdCAxIDAgUiAvU2l6ZSA1MyA+PgpzdGFydHhyZWYKMTQ5NDkKJSVFT0YK\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {\"AdaDFKD(S)\": \"star\", \"AdaDFKD(G)\": \"star\"}\n",
    "ax = sns.scatterplot(data=df, x='Time(h)', y='Acc@1', hue='method', markers=markers)\n",
    "ax.set(xscale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f81d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False\n",
    "gpu = 5\n",
    "# gpu ='0,1'\n",
    "batch_size = 128\n",
    "workers = 8\n",
    "num_classes = 10\n",
    "# num_classes = 100\n",
    "# num_classes = 200\n",
    "def prepare_model(model):\n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "        return model\n",
    "    elif distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if gpu is not None:\n",
    "#             torch.cuda.set_device(gpu)\n",
    "            model.cuda()\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            batch_size = int(batch_size / 1)\n",
    "            workers = int((workers + 1 - 1) / 1)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[int(x) for x in gpu.split(',')])\n",
    "            return model\n",
    "        else:\n",
    "            model.cuda()\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "            return model\n",
    "    elif gpu is not None:\n",
    "        torch.cuda.set_device(gpu)\n",
    "        model = model.cuda(gpu)\n",
    "        return model\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddea5407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10,CIFAR100\n",
    "import datafree\n",
    "import registry\n",
    "from torch import nn\n",
    "student = registry.get_model('resnet18', num_classes=num_classes)\n",
    "teacher = registry.get_model('resnet34', num_classes=num_classes, pretrained=True).eval()\n",
    "# student = registry.get_model('wrn40_1', num_classes=num_classes)\n",
    "# student= registry.get_model('wrn16_2', num_classes=num_classes)\n",
    "# teacher = registry.get_model('wrn40_2', num_classes=num_classes)\n",
    "# normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['tiny_imagenet'])\n",
    "# normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['cifar10'])\n",
    "normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['cifar100'])\n",
    "student = prepare_model(student)\n",
    "\n",
    "# teacher = teacher.to(gpu)\n",
    "# teacher.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "# num_ftrs = teacher.fc.in_features\n",
    "# teacher.fc = nn.Linear(num_ftrs, 200)\n",
    "# teacher.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "# teacher.maxpool = nn.Sequential()\n",
    "teacher = prepare_model(teacher)\n",
    "# ckpt = torch.load('../checkpoints/scratch/tiny_imagenet_resnet34_imagenet.pth', map_location='cpu')\n",
    "# dict_ckpt = dict()\n",
    "# for k, v in ckpt['state_dict'].items():\n",
    "#     dict_ckpt['.'.join(k.split('.')[1:])] = v\n",
    "# teacher.load_state_dict(dict_ckpt)\n",
    "\n",
    "teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar10_resnet34.pth', map_location='cpu')['state_dict'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar10_wrn40_2.pth', map_location='cpu')['state_dict'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar100_wrn40_2.pth', map_location='cpu')['state_dict'])\n",
    "# print(ckpt['best_acc1'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar100_resnet34.pth', map_location='cpu')['state_dict'])\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41af454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/data/lijingru/DFKD/run/cr4_sim_normalize_pos_c': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/lijingru/DFKD/run/cr4_sim_normalize_pos_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353c21e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-53fb9dbb976e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manchor_bank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# all_anchor = anchor_bank.reshape(-1, 512)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_bank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt'"
     ]
    }
   ],
   "source": [
    "anchor_bank = torch.load('/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt', map_location='cpu')\n",
    "# all_anchor = anchor_bank.reshape(-1, 512)\n",
    "print(anchor_bank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b27168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def difficulty_loss(anchor, teacher, t_out, logit_t, ds='cifar10', hard_factor=0., tau=10, device='cpu', d_neg_fea=None):\n",
    "    batch_size = anchor.size(0)\n",
    "    with torch.no_grad():\n",
    "        # t_logit, anchor_t_out = teacher(anchor.to(device).detach(), return_features=True)\n",
    "        t_logit = teacher(anchor.to(device).detach())\n",
    "        anchor_t_out = anchor.to(device)\n",
    "        # pseudo_label = pseudo_label.argmax(1)\n",
    "    # loss = 0.\n",
    "    pos_loss = 0.\n",
    "    neg_loss = 0.\n",
    "    if ds == 'cifar10':\n",
    "        normalized_anchor_t_out, normalized_t_out = F.normalize(anchor_t_out, dim=1), F.normalize(t_out, dim=1)\n",
    "        d = torch.mm(normalized_anchor_t_out, normalized_t_out.T)\n",
    "        N_an, N_batch = d.size()\n",
    "        \n",
    "        sorted_d, indice_d = torch.sort(d, dim=1)\n",
    "        d_pos = sorted_d[:, -int(0.05 * N_batch):]\n",
    "        d_neg = sorted_d[:, :-int(0.05 * N_batch)]\n",
    "        # n_neg = d_neg.size(1)\n",
    "        d_mask = torch.zeros_like(indice_d)\n",
    "        d_mask = d_mask.scatter(1, indice_d[:, -int(0.1*N_batch):], 1)\n",
    "        p_t_anchor = torch.softmax(t_logit, 1)\n",
    "        p_t_batch = torch.softmax(logit_t, 1)\n",
    "        kld_matrix = -torch.mm(p_t_anchor, p_t_batch.T.log()) + torch.diag(torch.mm(p_t_anchor, p_t_anchor.T.log())).unsqueeze(1)\n",
    "        l_kld = ((kld_matrix * d_mask).sum(1) / d_mask.sum(1)).mean()\n",
    "        # Get positive DA index\n",
    "        p_pos = torch.softmax(d_pos / tau, dim=1)\n",
    "        p_da_pos = torch.quantile(p_pos, q=1-hard_factor, dim=1).unsqueeze(1)\n",
    "        pos_loss = torch.sum(p_pos * torch.log(p_pos / p_da_pos).abs(), dim=1).mean()\n",
    "        # Get Negative DA index\n",
    "        \n",
    "        if d_neg_fea is not None:\n",
    "            d = torch.cat([d_neg, d_pos], 1)\n",
    "            d_mask = torch.zeros_like(d)\n",
    "#             d_mask[:, ]\n",
    "        p_total = torch.softmax(d / tau, dim=1)\n",
    "        # Out supervised loss.\n",
    "        print(d_mask, d_mask.shape)\n",
    "        neg_loss = -((d_mask * p_total.log()).sum(1) / (d_mask.sum(1))).mean()\n",
    "#         print(pos_loss, neg_loss, l_kld)\n",
    "        \n",
    "        return pos_loss, indice_d, neg_loss, l_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3874fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGAN_Generator_CIFAR10(\n",
       "  (project): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Linear(in_features=512, out_features=16384, bias=True)\n",
       "  )\n",
       "  (main): Sequential(\n",
       "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg = datafree.models.generator.DCGAN_Generator_CIFAR10(nz=512, ngf=64, nc=3, img_size=32, d=2, cond=False, type='normal', widen_factor=1)\n",
    "tg.load_state_dict(torch.load('/data1/lijingru/DFKD/checkpoints/datafree-improved_cudfkd/cifar10-resnet34-resnet18--infonce_s_exp6.pth', map_location='cpu')['G'])\n",
    "prepare_model(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dec2cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 2, 8, 2, 6, 0, 6, 0, 2, 8], device='cuda:5')\n"
     ]
    }
   ],
   "source": [
    "student.load_state_dict(torch.load('/data1/lijingru/DFKD/checkpoints/datafree-improved_cudfkd/cifar10-resnet34-resnet18--infonce_s_exp6.pth', map_location='cpu')['state_dict'])\n",
    "z = torch.randn(512, 512).to(gpu)\n",
    "x = normalizer(tg(z))\n",
    "t_out, t_feat = teacher(x, return_features=True)\n",
    "\n",
    "s_out, s_feat= student(x, return_features=True)\n",
    "tau = 0.07\n",
    "t_feat = torch.nn.functional.normalize(t_feat, dim=-1)\n",
    "s_feat = torch.nn.functional.normalize(s_feat, dim=-1)\n",
    "\n",
    "l_neg = t_feat @ s_feat.T\n",
    "_, indice_neg = torch.sort(l_neg, dim=1)\n",
    "\n",
    "balance = torch.nn.functional.cross_entropy(t_out, t_out.argmax(1), reduction='none')\n",
    "_ , index = torch.sort(balance)\n",
    "img_anchor = x[index[:10]].cpu()\n",
    "label = t_out[index[:10]].argmax(1)\n",
    "print(label)\n",
    "new_img = x.cpu()[indice_neg[index[:10]]]\n",
    "imgs = new_img.reshape(5120, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc50f321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5971e-02, 4.9913e-03, 4.8435e-04, 1.1491e-04, 6.2307e-02, 5.7498e-03,\n",
      "        1.7951e-04, 6.6437e-04, 4.7887e-04, 6.1286e-01, 1.2127e-02, 3.6090e-04,\n",
      "        1.7019e-03, 1.2994e-05, 2.5305e-02, 1.5854e-04, 4.3419e-04, 1.8120e-05,\n",
      "        1.4477e-01, 3.5065e-04, 1.4989e-03, 1.1420e-04, 2.0437e-01, 2.1738e-02,\n",
      "        3.8385e-05, 7.2150e-01, 8.9808e-04, 1.7343e-04, 3.8223e-04, 1.4066e-04,\n",
      "        3.9219e-05, 8.0208e-04, 5.1520e-01, 1.2898e-04, 1.2065e-01, 3.7653e-03,\n",
      "        2.8852e-03, 6.1629e-05, 4.8340e-04, 5.2118e-02, 2.6861e-02, 2.1320e-01,\n",
      "        2.8856e-04, 2.6995e-01, 4.6598e-01, 2.6723e-04, 5.1318e-04, 2.8630e-03,\n",
      "        3.2706e-04, 3.8578e-03, 2.0919e-01, 2.8749e-04, 4.1369e-04, 6.8200e-04,\n",
      "        5.4666e-03, 1.8004e-02, 6.1529e-04, 1.0475e+00, 3.0418e-04, 4.0590e-02,\n",
      "        2.5578e-02, 2.0443e-01, 8.7438e-04, 4.4751e-02, 1.0169e-02, 2.3386e-04,\n",
      "        7.3311e-05, 1.8726e-04, 1.7403e-04, 4.6731e-04, 1.4777e-03, 7.5695e-05,\n",
      "        9.5024e-04, 7.8147e-04, 3.0604e-01, 2.2397e-04, 4.5861e-04, 8.3168e-03,\n",
      "        7.1237e-03, 7.8742e-04, 9.9654e-05, 1.8704e-01, 4.0932e-02, 2.4328e-04,\n",
      "        1.7641e-03, 3.4072e-03, 3.4778e-02, 1.4709e-04, 4.3673e-02, 4.9424e-01,\n",
      "        1.7933e-01, 3.1049e-04, 6.2306e-01, 3.1669e-04, 5.9131e-01, 1.0466e-04,\n",
      "        2.5961e-01, 1.2335e-03, 5.7597e-04, 2.1134e-04, 4.2249e-03, 2.0417e-01,\n",
      "        2.8888e-02, 8.4829e-04, 5.0568e-04, 1.2931e-02, 2.0357e-01, 1.1072e+00,\n",
      "        4.4622e-04, 4.9416e-03, 9.9050e-04, 3.6802e-01, 3.4465e-01, 2.8215e-03,\n",
      "        5.7254e-01, 1.8236e-02, 4.3749e-05, 1.9860e-03, 1.5424e-04, 1.3196e-04,\n",
      "        1.4101e-04, 2.1026e-04, 6.1391e-05, 6.8365e-03, 5.6902e-02, 3.1728e-04,\n",
      "        1.0644e-02, 2.0434e-01, 6.0791e-02, 2.8940e-04, 1.4796e-03, 3.7311e-01,\n",
      "        2.7584e-02, 3.2038e-02, 1.0847e-04, 1.2504e-04, 1.1483e-02, 4.6781e-03,\n",
      "        2.6619e-01, 1.3351e-05, 1.4029e-03, 2.9173e-01, 1.3381e-01, 2.5376e-04,\n",
      "        6.3971e-04, 2.5128e-02, 1.5957e-03, 3.2309e-01, 1.6326e-02, 2.5736e-03,\n",
      "        7.0273e-04, 1.4221e-04, 1.8642e-02, 1.5079e-04, 6.9657e-01, 8.7377e-05,\n",
      "        9.0357e-05, 1.0689e-02, 8.5568e-04, 7.9415e-02, 1.9870e-04, 1.0015e-01,\n",
      "        2.4387e-04, 3.2312e-04, 1.0700e-02, 1.9970e-01, 4.4610e-04, 2.0678e-03,\n",
      "        1.9398e-01, 1.9437e-03, 2.4256e-04, 6.3459e-04, 2.2635e-04, 8.0601e-04,\n",
      "        1.0898e-03, 7.0927e-05, 2.0947e-02, 3.0899e-01, 9.7455e-02, 9.6441e-04,\n",
      "        6.0469e-04, 9.1549e-05, 6.0838e-04, 6.3775e-01, 1.0997e-01, 1.9432e-02,\n",
      "        2.8804e-02, 6.2583e-05, 6.6807e-03, 8.4059e-02, 1.0931e-04, 4.3454e-04,\n",
      "        1.8374e-03, 5.6191e-04, 1.1612e-01, 3.1319e-01, 8.5206e-01, 9.6361e-02,\n",
      "        2.9018e-01, 3.9942e-01, 5.4070e-03, 6.4734e-01, 1.4483e-04, 3.3826e-04,\n",
      "        3.4966e-01, 8.6788e-03, 9.8321e-02, 2.5960e-04, 3.0143e-04, 5.3094e-04,\n",
      "        1.6367e-02, 7.0450e-05, 3.4229e-01, 2.1315e-03, 1.3885e-02, 3.2467e-04,\n",
      "        3.2097e-02, 2.2401e-01, 9.8920e-03, 4.5418e-05, 2.9804e-03, 8.3424e-04,\n",
      "        6.2196e-04, 5.3091e-01, 5.0520e-04, 3.3506e-03, 3.9245e-03, 1.1400e-02,\n",
      "        1.6482e-02, 6.9219e-02, 2.6318e-04, 7.7397e-03, 5.0186e-05, 3.4148e-04,\n",
      "        2.2977e-01, 3.1121e-04, 1.0002e-02, 7.0450e-05, 4.5000e-02, 2.1085e-01,\n",
      "        3.8517e-01, 7.3440e-03, 2.7727e-03, 2.0442e-04, 3.2975e-03, 1.0883e-04,\n",
      "        5.1453e-01, 1.3068e-03, 5.4690e-04, 1.9148e-03, 9.9669e-04, 1.9300e-02,\n",
      "        1.0790e-03, 1.4280e-04, 6.2947e-04, 4.8947e-04, 9.9633e-04, 2.4609e-03,\n",
      "        3.7079e-04, 1.7916e-04, 3.1037e-01, 6.0676e-05, 1.2676e-03, 2.3948e-02,\n",
      "        6.2415e-02, 4.2060e-04, 4.0556e-02, 6.0683e-04, 1.4645e-02, 7.0875e-02,\n",
      "        2.3819e-03, 8.9430e-01, 3.2050e-04, 5.1222e-01, 4.0420e-01, 2.8513e-01,\n",
      "        4.0857e-04, 7.9598e-03, 4.9122e-01, 8.8449e-05, 7.3182e-02, 4.3131e-03,\n",
      "        2.1703e-02, 1.0408e-01, 2.5446e-03, 6.4376e-04, 2.6690e-01, 1.1728e-01,\n",
      "        2.4576e-02, 1.2439e-01, 1.2080e-01, 6.7259e-04, 3.0160e-01, 9.0120e-02,\n",
      "        2.0082e-03, 5.0373e-02, 2.0659e-01, 6.2303e-04, 3.7413e-04, 4.0030e-03,\n",
      "        1.4566e-04, 3.5371e-02, 1.4684e-01, 7.3669e-05, 1.5889e-02, 2.8504e-02,\n",
      "        2.8014e-05, 4.1461e-02, 1.9310e-04, 1.6447e-03, 5.8026e-04, 4.0338e-03,\n",
      "        4.6874e-04, 5.4883e-03, 2.7677e-04, 4.0247e-01, 2.2964e-02, 2.9161e-02,\n",
      "        3.4227e-01, 5.3643e-05, 7.9033e-05, 1.5069e-01, 5.6001e-04, 8.2185e-04,\n",
      "        1.8845e-04, 1.4409e-03, 5.2169e-02, 2.5519e-04, 2.5629e-03, 5.2057e-04,\n",
      "        3.6742e-02, 1.7129e-03, 7.2596e-05, 5.1688e-04, 2.3613e-04, 1.0003e-01,\n",
      "        2.6044e-04, 8.2254e-03, 1.1932e-04, 2.2372e-02, 3.9839e-02, 6.2339e-04,\n",
      "        8.6345e-03, 1.5202e-01, 1.4554e-04, 3.9772e-04, 1.5384e-03, 2.0268e-03,\n",
      "        9.3337e-05, 2.4602e-04, 2.6807e-04, 1.1421e-03, 3.4303e-04, 2.0981e-05,\n",
      "        2.6294e-03, 1.3577e-04, 3.9949e-02, 7.2119e-05, 3.9701e-04, 9.7747e-05,\n",
      "        4.8384e-01, 1.3351e-04, 2.2981e-04, 1.6736e-04, 5.3640e-02, 3.9297e-01,\n",
      "        6.2828e-03, 2.7817e-01, 1.4983e-04, 6.9151e-03, 5.3732e-03, 5.1402e-04,\n",
      "        4.0892e-04, 1.8171e-03, 1.0062e-03, 1.4654e-01, 1.0728e-04, 2.0836e-04,\n",
      "        1.2404e-01, 5.3404e-05, 2.9064e-03, 6.3298e-05, 6.9139e-05, 7.7960e-05,\n",
      "        3.0210e-03, 1.0001e-01, 1.5785e-03, 9.4171e-05, 4.5015e-04, 5.5817e-03,\n",
      "        4.5529e-02, 5.7335e-04, 4.1608e-01, 1.0037e-04, 4.7843e-01, 5.6287e-04,\n",
      "        3.6259e-01, 1.0917e-02, 6.8436e-02, 1.2681e-01, 3.3223e-03, 1.4435e-04,\n",
      "        1.1833e-03, 7.3120e-04, 2.7701e-01, 2.0037e-04, 4.8280e-04, 2.0318e-03,\n",
      "        1.0101e-01, 9.6477e-04, 1.7228e-01, 8.0225e-05, 7.5169e-04, 3.5510e-02,\n",
      "        3.8471e-02, 4.3932e-01, 2.3745e-01, 1.1719e-02, 2.9166e-04, 2.6610e-03,\n",
      "        4.6555e-03, 4.2572e-04, 4.8008e-03, 3.2150e-03, 1.2163e-02, 8.2609e-05,\n",
      "        5.9122e-04, 8.3038e-01, 3.1049e-04, 4.0282e-01, 1.8142e-04, 4.7017e-04,\n",
      "        2.2228e-02, 9.3170e-02, 9.9219e-03, 1.8905e-01, 2.3184e-04, 1.2627e-03,\n",
      "        1.7213e-03, 1.0465e-03, 2.1777e-04, 9.6446e-03, 2.6950e-04, 1.0540e-01,\n",
      "        3.4256e-01, 5.9742e-04, 6.2481e-03, 4.0234e-03, 1.8392e-04, 2.9993e-02,\n",
      "        4.7887e-04, 4.8268e-02, 1.0443e-01, 2.1126e-01, 7.9718e-02, 1.2314e-04,\n",
      "        1.1660e-02, 5.4154e-04, 5.3184e-01, 6.9177e-03, 3.7073e-05, 3.7603e-04,\n",
      "        1.4852e-03, 1.4514e-03, 4.3206e-03, 1.6462e-02, 3.7794e-04, 4.6952e-02,\n",
      "        2.0303e-03, 2.8451e-04, 8.9641e-05, 1.4604e-01, 7.7301e-02, 3.3269e-01,\n",
      "        2.3219e-04, 4.5867e-02, 9.9586e-02, 1.1522e-03, 1.8120e-05, 2.3863e-03,\n",
      "        2.4733e-04, 5.1688e-04, 6.8951e-03, 4.9722e-04, 1.1236e-01, 2.1169e-04,\n",
      "        1.5794e-04, 1.2385e-04, 3.9736e-04, 3.0632e-04, 3.2086e-04, 1.2119e-03,\n",
      "        6.9549e-01, 2.2534e-03, 1.9870e-04, 6.2732e-04, 2.1940e-03, 2.0418e-04,\n",
      "        1.4364e-04, 1.2963e-01, 5.3524e-05, 3.8235e-04, 4.5903e-01, 3.2879e-03,\n",
      "        2.3579e-02, 4.2346e-04, 7.2866e-01, 2.3936e-03, 4.1262e-04, 2.2457e-04,\n",
      "        3.6078e-04, 1.6652e-04], device='cuda:5', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb60d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100)\n",
      "tensor(0.1100)\n",
      "tensor(0.2100)\n",
      "tensor(0.3100)\n",
      "tensor(0.4100)\n",
      "tensor(0.5100)\n",
      "tensor(0.6100)\n",
      "tensor(0.7100)\n",
      "tensor(0.8100)\n",
      "tensor(0.9100)\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image,make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "img_list = []\n",
    "for i in torch.arange(0.01, 1.01, 0.1):\n",
    "    print(i)\n",
    "    img_list.append(new_img[:, -int(512 * i), :, :, :].unsqueeze(1))\n",
    "    \n",
    "img_list = torch.cat(img_list, 1)\n",
    "this_img = img_list.reshape(100, 3, 32, 32)\n",
    "img = make_grid(img_anchor, nrow=1, padding=2, normalize=True)\n",
    "neg_img = make_grid(this_img, nrow=10, padding=2, normalize=True)\n",
    "print(img.max(), img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bea2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d563ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(img, 'anchor.jpg')\n",
    "save_image(neg_img, 'neg2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04d5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
