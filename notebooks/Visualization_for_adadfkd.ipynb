{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a517e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import datafree\n",
    "%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a8453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 20 10:29:21 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 30%   21C    P8     5W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 70%   65C    P2   330W / 350W |  21725MiB / 24576MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 30%   19C    P8     3W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 31%   24C    P8    13W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 30%   20C    P8    16W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 30%   19C    P8    15W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     44121      C   python                          21723MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f81d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False\n",
    "gpu = 4\n",
    "# gpu ='0,1'\n",
    "batch_size = 128\n",
    "workers = 8\n",
    "num_classes = 10\n",
    "# num_classes = 100\n",
    "# num_classes = 200\n",
    "def prepare_model(model):\n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "        return model\n",
    "    elif distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if gpu is not None:\n",
    "#             torch.cuda.set_device(gpu)\n",
    "            model.cuda()\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            batch_size = int(batch_size / 1)\n",
    "            workers = int((workers + 1 - 1) / 1)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[int(x) for x in gpu.split(',')])\n",
    "            return model\n",
    "        else:\n",
    "            model.cuda()\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "            return model\n",
    "    elif gpu is not None:\n",
    "        torch.cuda.set_device(gpu)\n",
    "        model = model.cuda(gpu)\n",
    "        return model\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddea5407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10,CIFAR100\n",
    "import datafree\n",
    "import registry\n",
    "from torch import nn\n",
    "student = registry.get_model('resnet18', num_classes=num_classes)\n",
    "teacher = registry.get_model('resnet34', num_classes=num_classes, pretrained=True).eval()\n",
    "# student = registry.get_model('wrn40_1', num_classes=num_classes)\n",
    "# student= registry.get_model('wrn16_2', num_classes=num_classes)\n",
    "# teacher = registry.get_model('wrn40_2', num_classes=num_classes)\n",
    "# normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['tiny_imagenet'])\n",
    "# normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['cifar10'])\n",
    "normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT['cifar100'])\n",
    "student = prepare_model(student)\n",
    "\n",
    "# teacher = teacher.to(gpu)\n",
    "# teacher.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "# num_ftrs = teacher.fc.in_features\n",
    "# teacher.fc = nn.Linear(num_ftrs, 200)\n",
    "# teacher.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "# teacher.maxpool = nn.Sequential()\n",
    "teacher = prepare_model(teacher)\n",
    "# ckpt = torch.load('../checkpoints/scratch/tiny_imagenet_resnet34_imagenet.pth', map_location='cpu')\n",
    "# dict_ckpt = dict()\n",
    "# for k, v in ckpt['state_dict'].items():\n",
    "#     dict_ckpt['.'.join(k.split('.')[1:])] = v\n",
    "# teacher.load_state_dict(dict_ckpt)\n",
    "\n",
    "teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar10_resnet34.pth', map_location='cpu')['state_dict'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar10_wrn40_2.pth', map_location='cpu')['state_dict'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar100_wrn40_2.pth', map_location='cpu')['state_dict'])\n",
    "# print(ckpt['best_acc1'])\n",
    "# teacher.load_state_dict(torch.load('../checkpoints/scratch/cifar100_resnet34.pth', map_location='cpu')['state_dict'])\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41af454a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/lijingru/DFKD/run/cr4_sim_normalize_pos_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "353c21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_bank = torch.load('/data/lijingru/DFKD/run/cr6_sim_normalize_pos/buffer.pt', map_location='cpu')\n",
    "all_anchor = anchor_bank.reshape(-1, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b27168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def difficulty_loss(anchor, teacher, t_out, logit_t, ds='cifar10', hard_factor=0., tau=10, device='cpu'):\n",
    "    batch_size = anchor.size(0)\n",
    "#     print(t_out.size())\n",
    "    with torch.no_grad():\n",
    "        # t_logit, anchor_t_out = teacher(anchor.to(device).detach(), return_features=True)\n",
    "        t_logit = teacher(anchor.to(device).detach())\n",
    "        anchor_t_out = anchor.to(device)\n",
    "        # pseudo_label = pseudo_label.argmax(1)\n",
    "    # loss = 0.\n",
    "    pos_loss = 0.\n",
    "    neg_loss = 0.\n",
    "    if ds == 'cifar10':\n",
    "        normalized_anchor_t_out, normalized_t_out = F.normalize(anchor_t_out, dim=1), F.normalize(t_out, dim=1)\n",
    "        d = torch.mm(normalized_anchor_t_out, normalized_t_out.T)\n",
    "        N_an, N_batch = d.size()\n",
    "#         print(d.size())\n",
    "        # positive_negative_border = torch.quantile(d, q=0.1, dim=1)\n",
    "        # d_pos = d[:, d <= positive_negative_border]\n",
    "        # d_neg = d[:, d > positive_negative_border]\n",
    "        \n",
    "        sorted_d, indice_d = torch.sort(d, dim=1)\n",
    "        d_pos = sorted_d[:, -int(0.1 * N_batch):]\n",
    "        d_neg = sorted_d[:, :-int(0.1 * N_batch)]\n",
    "        d_mask = torch.zeros_like(indice_d)\n",
    "        d_mask = d_mask.scatter(1, indice_d[:, -int(0.1*N_batch):], 1)\n",
    "        p_t_anchor = torch.softmax(t_logit, 1)\n",
    "        p_t_batch = torch.softmax(logit_t, 1)\n",
    "        kld_matrix = -torch.mm(p_t_anchor, p_t_batch.T.log()) + torch.diag(torch.mm(p_t_anchor, p_t_anchor.T.log())).unsqueeze(1)\n",
    "        l_kld = ((kld_matrix * d_mask).sum(1) / d_mask.sum(1)).mean()\n",
    "        # Get positive DA index\n",
    "        p_pos = torch.softmax(d_pos / tau, dim=1)\n",
    "        p_da_pos = torch.quantile(p_pos, q=1-hard_factor, dim=1).unsqueeze(1)\n",
    "        pos_loss = torch.sum(p_pos * torch.log(p_pos / p_da_pos).abs(), dim=1).mean()\n",
    "#         print(p_pos)\n",
    "        # Get Negative DA index\n",
    "        p_neg = torch.softmax(d_neg / tau, dim=1)\n",
    "        p_da_neg = torch.quantile(p_neg, q=hard_factor, dim=1).unsqueeze(1)\n",
    "        neg_loss = torch.sum(p_neg * torch.log(p_neg / p_da_neg).abs(), dim=1).sum()\n",
    "        print(p_pos, p_neg)\n",
    "        # print(pos_loss, neg_loss)\n",
    "        return pos_loss, indice_d, neg_loss, l_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3874fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGAN_Generator_CIFAR10(\n",
       "  (project): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Linear(in_features=512, out_features=16384, bias=True)\n",
       "  )\n",
       "  (main): Sequential(\n",
       "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg = datafree.models.generator.DCGAN_Generator_CIFAR10(nz=512, ngf=64, nc=3, img_size=32, d=2, cond=False, type='normal', widen_factor=1)\n",
    "tg.load_state_dict(torch.load('/data/lijingru/DFKD/checkpoints/datafree-improved_cudfkd/cifar10-resnet34-resnet18--cr6_sim_normalize_pos.pth', map_location='cpu')['G'])\n",
    "prepare_model(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dec2cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0081, 0.0085, 0.0088,  ..., 0.0449, 0.0452, 0.0466],\n",
      "        [0.0088, 0.0092, 0.0092,  ..., 0.0517, 0.0643, 0.0685],\n",
      "        [0.0114, 0.0116, 0.0119,  ..., 0.0310, 0.0322, 0.0334],\n",
      "        ...,\n",
      "        [0.0095, 0.0097, 0.0098,  ..., 0.0513, 0.0513, 0.0639],\n",
      "        [0.0097, 0.0098, 0.0098,  ..., 0.0561, 0.0633, 0.0857],\n",
      "        [0.0076, 0.0076, 0.0078,  ..., 0.0346, 0.0377, 0.0549]],\n",
      "       device='cuda:4', grad_fn=<SoftmaxBackward>) tensor([[2.9098e-05, 2.9663e-05, 3.5243e-05,  ..., 1.6713e-02, 1.6976e-02,\n",
      "         1.7073e-02],\n",
      "        [2.7356e-05, 3.3205e-05, 4.0463e-05,  ..., 1.5509e-02, 1.5820e-02,\n",
      "         1.5960e-02],\n",
      "        [2.4320e-05, 2.4642e-05, 3.3066e-05,  ..., 2.6294e-02, 2.6789e-02,\n",
      "         2.7016e-02],\n",
      "        ...,\n",
      "        [4.0547e-05, 4.2399e-05, 4.3937e-05,  ..., 1.1529e-02, 1.1621e-02,\n",
      "         1.1677e-02],\n",
      "        [2.3966e-05, 2.8157e-05, 2.8915e-05,  ..., 1.2259e-02, 1.2261e-02,\n",
      "         1.2564e-02],\n",
      "        [2.0360e-05, 2.2452e-05, 2.4741e-05,  ..., 1.3238e-02, 1.3909e-02,\n",
      "         1.3991e-02]], device='cuda:4', grad_fn=<SoftmaxBackward>)\n",
      "tensor(0.9409, device='cuda:4', grad_fn=<MeanBackward0>) tensor([[465, 264, 138,  ..., 322,  21, 281],\n",
      "        [ 41,  24, 236,  ..., 183, 290,  56],\n",
      "        [463, 263, 154,  ..., 193, 148,  60],\n",
      "        ...,\n",
      "        [358,  41, 319,  ..., 250, 406, 430],\n",
      "        [230,  69, 261,  ...,  13, 365, 311],\n",
      "        [431, 458, 507,  ..., 502, 326, 477]], device='cuda:4') tensor(44682.2070, device='cuda:4', grad_fn=<SumBackward0>) tensor(1.1299, device='cuda:4', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.randn(512, 512).to(gpu)\n",
    "x = normalizer(tg(z))\n",
    "t_out, t_feat = teacher(x, return_features=True)\n",
    "\n",
    "a, b, c, d = difficulty_loss(all_anchor, teacher.linear, t_feat, logit_t=t_out, device=gpu, hard_factor=0., tau=0.07)\n",
    "print(a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cb60d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image,make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "indexs = b[:, :-int(0.1*512)]\n",
    "img = make_grid(x[indexs[0]], nrow=7, padding=2, value_range=(0, 1))\n",
    "# plt.show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bea2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d563ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(img, 'neg1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
